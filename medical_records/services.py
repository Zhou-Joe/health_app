import requests
import json
import time
import re
import base64
from datetime import datetime
from django.conf import settings
from .models import DocumentProcessing, HealthIndicator, SystemSettings


class DocumentProcessingService:
    """æ–‡æ¡£å¤„ç†æœåŠ¡ç±»"""

    def __init__(self, document_processing):
        self.document_processing = document_processing
        # ä»æ•°æ®åº“è·å–åŠ¨æ€é…ç½®
        self.mineru_api_url = SystemSettings.get_setting('mineru_api_url', 'http://localhost:8000')
        # è¯»å–æ•°æ®æ•´åˆLLMçš„é…ç½®
        self.llm_provider = SystemSettings.get_setting('llm_provider', 'openai')
        self.llm_api_url = SystemSettings.get_setting('llm_api_url', 'http://172.25.48.1:1234')
        self.llm_api_key = SystemSettings.get_setting('llm_api_key', '')
        self.llm_model_name = SystemSettings.get_setting('llm_model_name', 'qwen3-4b-instruct')
        # ä½¿ç”¨ç»Ÿä¸€çš„AIæ¨¡å‹è¶…æ—¶é…ç½®
        self.ai_timeout = int(SystemSettings.get_setting('ai_model_timeout', '300'))
        # ä½¿ç”¨æ–‡æ¡£å¤„ç†çš„max_tokensé…ç½®
        self.document_max_tokens = int(SystemSettings.get_setting('document_max_tokens', '8000'))

    def update_progress(self, status, progress, message=None, is_error=False):
        """æ›´æ–°å¤„ç†è¿›åº¦"""
        self.document_processing.status = status
        self.document_processing.progress = progress
        if message and is_error:
            # åªæœ‰åœ¨æ˜ç¡®æ ‡è®°ä¸ºé”™è¯¯æ—¶æ‰è®¾ç½®error_message
            self.document_processing.error_message = message
        elif message and not is_error:
            # å¯¹äºæ­£å¸¸çš„è¿›åº¦æ¶ˆæ¯ï¼Œæ¸…é™¤ä¹‹å‰çš„é”™è¯¯ä¿¡æ¯
            self.document_processing.error_message = None
        self.document_processing.save()

    def perform_ocr(self, file_path):
        """è°ƒç”¨MinerU APIè¿›è¡ŒOCRè¯†åˆ«"""
        try:
            self.update_progress('ocr_processing', 20, "å¼€å§‹OCRè¯†åˆ«...")

            # å‡†å¤‡æ–‡ä»¶ä¸Šä¼  - MinerUéœ€è¦filesæ•°ç»„
            with open(file_path, 'rb') as f:
                files = {'files': f}
                
                # æ ¹æ®å·¥ä½œæµç±»å‹é€‰æ‹©backend
                workflow_type = getattr(self.document_processing, 'workflow_type', 'ocr_llm')
                if workflow_type == 'vlm_transformers':
                    backend = 'vlm-transformers'  # ä½¿ç”¨VLM-Transformersæ¨¡å¼
                else:
                    backend = 'pipeline'  # ä¼ ç»ŸOCRæ¨¡å¼
                    
                data = {
                    'parse_method': 'auto',  # è‡ªåŠ¨è¯†åˆ«ç±»å‹
                    'lang_list': 'ch',        # ä¸­æ–‡è¯†åˆ« (å­—ç¬¦ä¸²æ ¼å¼)
                    'return_md': True,        # è¿”å›markdownæ ¼å¼
                    'formula_enable': True,   # å¯ç”¨å…¬å¼è¯†åˆ«
                    'table_enable': True,     # å¯ç”¨è¡¨æ ¼è¯†åˆ«
                    'backend': backend        # é€‰æ‹©å¤„ç†backend
                }

                # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„MinerUç«¯ç‚¹
                api_url = self.mineru_api_url
                if not api_url.endswith('/file_parse'):
                    api_url = f"{api_url.rstrip('/')}/file_parse"

                # è°ƒç”¨MinerU API
                response = requests.post(
                    api_url,
                    files=files,
                    data=data,
                    timeout=self.ai_timeout  # ä½¿ç”¨ç»Ÿä¸€çš„è¶…æ—¶è®¾ç½®
                )

            if response.status_code == 200:
                result = response.json()

                # MinerUè¿”å›çš„æ ¼å¼æ˜¯åµŒå¥—çš„ï¼šresults -> {filename} -> md_content
                ocr_text = ""

                try:
                    if 'results' in result:
                        results = result['results']
                        # è·å–ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„markdownå†…å®¹
                        first_file_key = list(results.keys())[0]
                        if first_file_key in results:
                            file_result = results[first_file_key]
                            if 'md_content' in file_result:
                                ocr_text = file_result['md_content']

                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°md_contentï¼Œå°è¯•å…¶ä»–å­—æ®µ
                    if not ocr_text:
                        # å°è¯•ä»ä¸åŒçš„å­—æ®µæå–æ–‡æœ¬
                        if isinstance(result, dict):
                            if 'content' in result:
                                ocr_text = result['content']
                            elif 'text' in result:
                                ocr_text = result['text']
                            elif isinstance(result, list) and len(result) > 0:
                                # å¦‚æœè¿”å›æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ çš„æ–‡æœ¬
                                first_item = result[0]
                                if isinstance(first_item, dict):
                                    ocr_text = first_item.get('content', '') or first_item.get('text', '')
                            else:
                                # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„æ–‡æœ¬å­—æ®µï¼Œå°è¯•è½¬æ¢æ•´ä¸ªç»“æœ
                                import json
                                ocr_text = json.dumps(result, ensure_ascii=False, indent=2)
                        else:
                            ocr_text = str(result)

                except Exception as parse_error:
                    print(f"è§£æMinerUç»“æœæ—¶å‡ºé”™: {parse_error}")
                    ocr_text = str(result)

                if not ocr_text.strip():
                    raise Exception("OCRè¯†åˆ«è¿”å›ç©ºç»“æœ")

                self.document_processing.ocr_result = ocr_text
                self.document_processing.save()

                self.update_progress('ocr_processing', 40, "OCRè¯†åˆ«å®Œæˆ")
                return ocr_text
            else:
                raise Exception(f"OCR APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")

        except Exception as e:
            self.update_progress('failed', 0, f"OCRè¯†åˆ«å¤±è´¥: {str(e)}", is_error=True)
            raise

    def process_with_llm(self, ocr_text):
        """è°ƒç”¨LLMè¿›è¡Œæ•°æ®ç»“æ„åŒ–å¤„ç†"""
        try:
            self.update_progress('ai_processing', 50, "å¼€å§‹AIæ•°æ®åˆ†æ...")

            # åªè°ƒç”¨ModelScope LLMï¼Œä¸ä½¿ç”¨è§„åˆ™å¼•æ“
            print("å¼€å§‹è°ƒç”¨ModelScope LLM...")
            structured_data = self._call_real_llm(ocr_text)

            # ä¿å­˜LLMåŸå§‹ç»“æœç”¨äºè°ƒè¯•
            self.document_processing.ai_result = structured_data
            self.document_processing.save()
            print(f"LLMç»“æœå·²ä¿å­˜ï¼ŒåŒ…å« {len(structured_data.get('indicators', []))} ä¸ªæŒ‡æ ‡")

            self.update_progress('ai_processing', 70, "AIæ•°æ®åˆ†æå®Œæˆ")
            return structured_data

        except Exception as e:
            # ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°æ•°æ®åº“
            error_msg = f"LLMå¤„ç†å¤±è´¥: {str(e)}"
            self.document_processing.error_message = error_msg
            self.document_processing.save()
            print(f"LLMå¤„ç†å¤±è´¥: {error_msg}")

            self.update_progress('failed', 0, error_msg, is_error=True)
            raise

    def _call_real_llm(self, ocr_text):
        """è°ƒç”¨LLMæœåŠ¡è¿›è¡Œæ–‡æ¡£åˆ†æ"""
        print(f"\n{'='*60}")
        print(f"ğŸ§  [LLMæœåŠ¡] å¼€å§‹è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹")
        print(f"ğŸ“ OCRæ–‡æœ¬é•¿åº¦: {len(ocr_text)} å­—ç¬¦")
        print(f"ğŸ“ OCRæ–‡æœ¬å‰200å­—ç¬¦: {ocr_text[:200]}...")
        print(f"ğŸ”§ LLMæä¾›å•†: {self.llm_provider}")

        # æ„å»ºprompt
        prompt = self._build_llm_prompt(ocr_text)
        print(f"ğŸ“‹ æ„å»ºå®ŒæˆPromptï¼Œé•¿åº¦: {len(prompt)} å­—ç¬¦")

        # æ ¹æ®providerç±»å‹è°ƒç”¨ä¸åŒçš„API
        if self.llm_provider == 'gemini':
            return self._call_gemini_api(ocr_text, prompt)
        else:
            return self._call_openai_compatible_api(ocr_text, prompt)

    def _call_gemini_api(self, ocr_text, prompt):
        """è°ƒç”¨Gemini API"""
        from .models import SystemSettings

        # è·å–Geminié…ç½®
        gemini_config = SystemSettings.get_gemini_config()
        api_key = gemini_config['api_key']
        model_name = gemini_config['model_name']

        if not api_key:
            raise Exception("Gemini APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨ç³»ç»Ÿè®¾ç½®ä¸­é…ç½®")

        # æ„å»ºGemini APIè¯·æ±‚
        gemini_data = {
            "contents": [{
                "parts": [
                    {
                        "text": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œè¯·ä»ä½“æ£€æŠ¥å‘ŠOCRæ–‡æœ¬ä¸­æå–å¥åº·æŒ‡æ ‡æ•°æ®ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¿”å›ã€‚"
                    },
                    {
                        "text": prompt
                    }
                ]
            }],
            "generationConfig": {
                "temperature": 0.1,
                "maxOutputTokens": self.document_max_tokens
            }
        }

        api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"

        print(f"ğŸŒ Gemini APIé…ç½®ä¿¡æ¯:")
        print(f"   - API URL: {api_url[:100]}...")
        print(f"   - æ¨¡å‹åç§°: {model_name}")
        print(f"   - è¶…æ—¶æ—¶é—´: {self.ai_timeout}ç§’")
        print(f"   - æœ€å¤§ä»¤ç‰Œæ•°: {self.document_max_tokens}")

        try:
            import time
            start_time = time.time()

            response = requests.post(
                api_url,
                json=gemini_data,
                timeout=self.ai_timeout
            )

            end_time = time.time()
            print(f"â±ï¸  è¯·æ±‚è€—æ—¶: {end_time - start_time:.2f} ç§’")
            print(f"ğŸ“¥ APIå“åº”çŠ¶æ€ç : {response.status_code}")

            if response.status_code == 200:
                result = response.json()
                # æå–Geminiçš„å“åº”æ–‡æœ¬
                if 'candidates' in result and len(result['candidates']) > 0:
                    llm_response_text = result['candidates'][0]['content']['parts'][0]['text']
                    print(f"âœ… Gemini APIè°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(llm_response_text)} å­—ç¬¦")
                    print(f"ğŸ“„ å“åº”å†…å®¹å‰200å­—ç¬¦: {llm_response_text[:200]}...")

                    # æ¸…ç†å“åº”ï¼Œç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
                    cleaned_response = llm_response_text.strip()
                    if cleaned_response.startswith('```json'):
                        cleaned_response = cleaned_response[7:]
                    elif cleaned_response.startswith('```'):
                        cleaned_response = cleaned_response[3:]
                    if cleaned_response.endswith('```'):
                        cleaned_response = cleaned_response[:-3]
                    cleaned_response = cleaned_response.strip()

                    print(f"ğŸ§¹ æ¸…ç†åçš„å“åº”å‰200å­—ç¬¦: {cleaned_response[:200]}...")

                    # è§£æJSONå“åº”
                    try:
                        structured_data = json.loads(cleaned_response)
                        indicators_count = len(structured_data.get('indicators', []))
                        print(f"âœ… JSONè§£ææˆåŠŸï¼ŒåŒ…å« {indicators_count} ä¸ªæŒ‡æ ‡")
                        return structured_data
                    except json.JSONDecodeError as e:
                        print(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
                        print(f"ğŸ“„ å®Œæ•´å“åº”å†…å®¹:\n{llm_response_text}")
                        raise Exception(f"Geminiè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {str(e)}")
                else:
                    raise Exception("Gemini APIè¿”å›æ ¼å¼é”™è¯¯ï¼šæ²¡æœ‰candidates")
            else:
                raise Exception(f"Gemini APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")

        except requests.exceptions.Timeout:
            print(f"âŒ Gemini APIè°ƒç”¨è¶…æ—¶ï¼ˆè¶…è¿‡{self.ai_timeout}ç§’ï¼‰")
            raise Exception(f"Gemini APIè°ƒç”¨è¶…æ—¶")
        except Exception as e:
            print(f"âŒ Gemini APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise

    def _call_openai_compatible_api(self, ocr_text, prompt):
        """è°ƒç”¨OpenAIå…¼å®¹æ ¼å¼çš„API"""
        # å‡†å¤‡æœ¬åœ°LLM APIè¯·æ±‚
        llm_data = {
            "model": self.llm_model_name,
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œè¯·ä»ä½“æ£€æŠ¥å‘ŠOCRæ–‡æœ¬ä¸­æå–å¥åº·æŒ‡æ ‡æ•°æ®ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¿”å›ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.1,
            "max_tokens": self.document_max_tokens
        }

        # å‡†å¤‡è¯·æ±‚å¤´
        headers = {
            "Content-Type": "application/json"
        }

        # åªæœ‰åœ¨æœ‰API Keyæ—¶æ‰æ·»åŠ Authorizationå¤´
        if self.llm_api_key:
            headers["Authorization"] = f"Bearer {self.llm_api_key}"

        try:
            print(f"ğŸŒ OpenAIå…¼å®¹APIé…ç½®ä¿¡æ¯:")
            print(f"   - API URL: {self.llm_api_url}")
            print(f"   - æ¨¡å‹åç§°: {self.llm_model_name}")
            print(f"   - è¶…æ—¶æ—¶é—´: {self.ai_timeout}ç§’")
            print(f"   - æœ€å¤§ä»¤ç‰Œæ•°: {self.document_max_tokens}")
            print(f"   - API Key: {'å·²è®¾ç½®' if self.llm_api_key else 'æœªè®¾ç½®'}")

            # ç›´æ¥ä½¿ç”¨é…ç½®çš„å®Œæ•´APIåœ°å€
            api_url = self.llm_api_url
            print(f"ğŸ”§ ä½¿ç”¨APIåœ°å€: {api_url}")

            print(f"ğŸ“¤ è¯·æ±‚æ•°æ®å¤§å°: {len(json.dumps(llm_data))} å­—ç¬¦")

            # è®°å½•è¯·æ±‚å¼€å§‹æ—¶é—´
            import time
            start_time = time.time()

            print(f"ğŸš€ æ­£åœ¨å‘é€è¯·æ±‚åˆ°LLMæœåŠ¡...")
            response = requests.post(
                api_url,
                json=llm_data,
                headers=headers,
                timeout=self.ai_timeout
            )

            # è®¡ç®—è¯·æ±‚è€—æ—¶
            end_time = time.time()
            request_duration = end_time - start_time

            print(f"â±ï¸  è¯·æ±‚è€—æ—¶: {request_duration:.2f} ç§’")
            print(f"ğŸ“¥ APIå“åº”çŠ¶æ€ç : {response.status_code}")
            print(f"ğŸ“¥ APIå“åº”å¤§å°: {len(response.text)} å­—ç¬¦")
            print(f"ğŸ“¥ APIå“åº”å‰500å­—ç¬¦: {response.text[:500]}...")

            if response.status_code == 200:
                result = response.json()
                # OpenAIå…¼å®¹æ ¼å¼çš„å“åº”è§£æ
                if 'choices' in result and len(result['choices']) > 0:
                    llm_response_text = result['choices'][0]['message']['content']
                    print(f"âœ… OpenAIå…¼å®¹APIè°ƒç”¨æˆåŠŸ")
                    print(f"ğŸ“„ LLMå“åº”é•¿åº¦: {len(llm_response_text)} å­—ç¬¦")

                    # æ¸…ç†å“åº”ï¼Œç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
                    cleaned_response = llm_response_text.strip()
                    if cleaned_response.startswith('```json'):
                        cleaned_response = cleaned_response[7:]
                    elif cleaned_response.startswith('```'):
                        cleaned_response = cleaned_response[3:]
                    if cleaned_response.endswith('```'):
                        cleaned_response = cleaned_response[:-3]
                    cleaned_response = cleaned_response.strip()

                    print(f"ğŸ§¹ æ¸…ç†åçš„å“åº”å‰200å­—ç¬¦: {cleaned_response[:200]}...")

                    # å°è¯•è§£æJSON
                    try:
                        structured_data = json.loads(cleaned_response)
                        print(f"âœ… JSONè§£ææˆåŠŸï¼ŒåŒ…å« {len(structured_data.get('indicators', []))} ä¸ªæŒ‡æ ‡")
                        return structured_data
                    except json.JSONDecodeError as e:
                        print(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
                        print(f"ğŸ“„ å®Œæ•´LLMå“åº”å†…å®¹:\n{llm_response_text}")
                        raise Exception(f"LLMè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {str(e)}")
                else:
                    raise Exception("APIè¿”å›æ ¼å¼é”™è¯¯ï¼šæ²¡æœ‰choiceså­—æ®µ")
            else:
                raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")

        except requests.exceptions.Timeout:
            print(f"âŒ LLM APIè°ƒç”¨è¶…æ—¶ (è¶…è¿‡{self.ai_timeout}ç§’)")
            raise Exception("æœ¬åœ°LLM APIè°ƒç”¨è¶…æ—¶")
        except requests.exceptions.RequestException as e:
            print(f"âŒ LLM APIç½‘ç»œé”™è¯¯: {str(e)}")
            raise Exception(f"æœ¬åœ°LLM APIç½‘ç»œé”™è¯¯: {str(e)}")
        except Exception as e:
            print(f"âŒ LLM APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise

    def _get_indicator_type_from_name(self, indicator_name):
        """æ ¹æ®æŒ‡æ ‡åç§°ç¡®å®šæŒ‡æ ‡ç±»å‹ï¼ˆæ–°çš„11ç§åˆ†ç±»ï¼‰"""

        # ä½“æ ¼æ£€æŸ¥ï¼šåŸºç¡€ä½“å¾ã€ä½“æ ¼æµ‹é‡ã€è§†åŠ›ç­‰
        physical_exam_keywords = [
            'èº«é«˜', 'ä½“é‡', 'ä½“é‡æŒ‡æ•°', 'è…°å›´', 'è‡€å›´', 'è…°å›´è‡€å›´æ¯”å€¼', 'èƒ¸å›´',
            'è¡€å‹', 'æ”¶ç¼©å‹', 'èˆ’å¼ å‹', 'ä½“æ¸©', 'è„‰æ', 'å¿ƒç‡', 'å‘¼å¸é¢‘ç‡',
            'è§†åŠ›', 'è£¸çœ¼è§†åŠ›', 'çŸ«æ­£è§†åŠ›', 'çœ¼å‹', 'çœ¼åº•', 'å¬åŠ›', 'å³çœ¼è§†åŠ›', 'å·¦çœ¼è§†åŠ›',
            'å³çœ¼çœ¼å‹å€¼', 'å·¦çœ¼çœ¼å‹å€¼'
        ]

        # è¡€æ¶²å¸¸è§„ï¼šè¡€å¸¸è§„ç›¸å…³æŒ‡æ ‡
        blood_routine_keywords = [
            'ç™½ç»†èƒ', 'çº¢ç»†èƒ', 'è¡€çº¢è›‹ç™½', 'è¡€å°æ¿', 'è¡€ç»†èƒ',
            'ä¸­æ€§ç²’ç»†èƒ', 'æ·‹å·´ç»†èƒ', 'å•æ ¸ç»†èƒ', 'å—œé…¸æ€§', 'å—œç¢±æ€§',
            'çº¢ç»†èƒæ¯”å®¹', 'çº¢ç»†èƒåˆ†å¸ƒå®½åº¦', 'å¹³å‡è¡€çº¢è›‹ç™½', 'å¹³å‡çº¢ç»†èƒ',
            'è¡€å°æ¿å‹ç§¯', 'è¡€å°æ¿åˆ†å¸ƒå®½åº¦', 'å¹³å‡è¡€å°æ¿', 'å¤§è¡€å°æ¿',
            'è¡€æ²‰', 'è¡€æ²‰æ–¹ç¨‹Kå€¼', 'çº¢ç»†èƒè®¡æ•°', 'è¡€çº¢è›‹ç™½æµ“åº¦', 'å¹³å‡çº¢ç»†èƒå®¹ç§¯',
            'ä¸­æ€§ç²’ç»†èƒç™¾åˆ†æ¯”', 'ä¸­æ€§ç²’ç»†èƒç»å¯¹è®¡æ•°', 'æ·‹å·´ç»†èƒç™¾åˆ†æ¯”', 'æ·‹å·´ç»†èƒç»å¯¹è®¡æ•°',
            'å•æ ¸ç»†èƒç™¾åˆ†æ¯”', 'å•æ ¸ç»†èƒç»å¯¹è®¡æ•°', 'å—œé…¸æ€§ç²’ç»†èƒç™¾åˆ†æ¯”', 'å—œé…¸æ€§ç²’ç»†èƒç»å¯¹è®¡æ•°',
            'å—œç¢±æ€§ç²’ç»†èƒç™¾åˆ†æ¯”', 'å—œç¢±æ€§ç²’ç»†èƒç»å¯¹è®¡æ•°', 'è¡€å°æ¿è®¡æ•°', 'è¡€å°æ¿åˆ†å¸ƒå®½åº¦',
            'å¹³å‡è¡€å°æ¿å®¹ç§¯', 'è¡€å°æ¿å‹ç§¯', 'å¤§è¡€å°æ¿è®¡æ•°', 'å¤§è¡€å°æ¿æ¯”ä¾‹'
        ]

        # ç”ŸåŒ–æ£€éªŒï¼šç”ŸåŒ–ç›¸å…³æŒ‡æ ‡
        biochemistry_keywords = [
            'è¡€ç³–', 'è‘¡è„ç³–', 'ç©ºè…¹è¡€ç³–', 'é¤åè¡€ç³–', 'ç³–åŒ–è¡€çº¢è›‹ç™½',
            'èƒ†å›ºé†‡', 'ç”˜æ²¹ä¸‰é…¯', 'é«˜å¯†åº¦è„‚è›‹ç™½', 'ä½å¯†åº¦è„‚è›‹ç™½',
            'æ€»èƒ†å›ºé†‡', 'é«˜å¯†åº¦è„‚è›‹ç™½èƒ†å›ºé†‡', 'ä½å¯†åº¦è„‚è›‹ç™½èƒ†å›ºé†‡',
            'è½½è„‚è›‹ç™½', 'è„‚è›‹ç™½', 'å°¿ç´ ', 'å°¿ç´ æ°®', 'è‚Œé…', 'å°¿é…¸',
            'æ€»èƒ†çº¢ç´ ', 'ç›´æ¥èƒ†çº¢ç´ ', 'é—´æ¥èƒ†çº¢ç´ ', 'è¡€æµ†ç²˜åº¦', 'ç»´ç”Ÿç´ C',
            'è½½è„‚è›‹ç™½A1', 'è½½è„‚è›‹ç™½B'
        ]

        # è‚åŠŸèƒ½ï¼šä¸“é—¨çš„è‚åŠŸèƒ½æŒ‡æ ‡
        liver_function_keywords = [
            'ä¸™æ°¨é…¸æ°¨åŸºè½¬ç§»é…¶', 'å¤©é—¨å†¬æ°¨é…¸æ°¨åŸºè½¬ç§»é…¶', 'Î³-è°·æ°¨é…°è½¬ç§»é…¶'
        ]

        # è‚¾åŠŸèƒ½ï¼šä¸“é—¨çš„è‚¾åŠŸèƒ½æŒ‡æ ‡
        kidney_function_keywords = [
            'å°¿è‚Œé…', 'å°¿å¾®é‡ç™½è›‹ç™½'
        ]

        # ç”²çŠ¶è…ºåŠŸèƒ½ï¼šç”²çŠ¶è…ºç›¸å…³æŒ‡æ ‡
        thyroid_function_keywords = [
            'ç”²çŠ¶è…º', 'TSH', 'T3', 'T4', 'ä¿ƒç”²çŠ¶è…ºæ¿€ç´ ',
            'æ¸¸ç¦»ä¸‰ç¢˜ç”²çŠ¶è…ºåŸæ°¨é…¸', 'æ¸¸ç¦»ç”²çŠ¶è…ºç´ ', 'ç”²çŠ¶è…ºç´ ',
            'ä¸‰ç¢˜ç”²çŠ¶è…ºåŸæ°¨é…¸', 'è¡€æ¸…æ¸¸ç¦»ä¸‰ç¢˜ç”²çŠ¶è…ºåŸæ°¨é…¸'
        ]

        # è‚¿ç˜¤æ ‡å¿—ç‰©ï¼šè‚¿ç˜¤ç›¸å…³æŒ‡æ ‡
        tumor_markers_keywords = [
            'ç™ŒèƒšæŠ—åŸ', 'ç”²èƒè›‹ç™½', 'å‰åˆ—è…ºç‰¹å¼‚æ€§æŠ—åŸ', 'æ¸¸ç¦»å‰åˆ—è…ºç‰¹å¼‚æ€§æŠ—åŸ',
            'ç³–ç±»æŠ—åŸ19-9', 'ç³–é“¾æŠ—åŸ19-9', 'ç»†èƒè§’è›‹ç™½19ç‰‡æ®µæŠ—åŸ', 'CEA', 'AFP', 'CA',
            'è‚¿ç˜¤æ ‡å¿—ç‰©'
        ]

        # å°¿æ¶²æ£€æŸ¥ï¼šå°¿å¸¸è§„ç›¸å…³æŒ‡æ ‡
        urine_exam_keywords = [
            'å°¿è›‹ç™½', 'å°¿ç³–', 'å°¿æ¯”é‡', 'å°¿é…¸ç¢±åº¦', 'å°¿æ½œè¡€', 'å°¿pHå€¼',
            'å°¿ç™½ç»†èƒ', 'å°¿çº¢ç»†èƒ', 'å°¿é…®ä½“', 'å°¿èƒ†åŸ', 'å°¿èƒ†çº¢ç´ ', 'å°¿èƒ†ç´ ',
            'å°¿å¸¸è§„', 'å°¿æ£€', 'å°¿æ¶²', 'å°¿ç®¡å‹', 'å°¿ç»“æ™¶', 'ä¸Šçš®ç»†èƒ', 'å°¿é’™'
        ]

        # è¡€æ¶²æµå˜å­¦ï¼šè¡€æ¶²ç²˜åº¦ç›¸å…³æŒ‡æ ‡
        blood_rheology_keywords = [
            'å…¨è¡€ç²˜åº¦', 'å…¨è¡€è¿˜åŸç²˜åº¦', 'è¡€æµ†ç²˜åº¦',
            'ä½åˆ‡', 'é«˜åˆ‡', 'ç›¸å¯¹æŒ‡æ•°', 'åˆšæ€§æŒ‡æ•°', 'å˜å½¢æŒ‡æ•°', 'èšé›†æŒ‡æ•°'
        ]

        # çœ¼ç§‘æ£€æŸ¥ï¼šçœ¼ç§‘ç›¸å…³æŒ‡æ ‡
        eye_exam_keywords = [
            'è§†åŠ›', 'è£¸çœ¼è§†åŠ›', 'çŸ«æ­£è§†åŠ›', 'çœ¼å‹', 'å³çœ¼è§†åŠ›', 'å·¦çœ¼è§†åŠ›',
            'å³çœ¼çœ¼å‹å€¼', 'å·¦çœ¼çœ¼å‹å€¼', 'çœ¼åº•', 'å¬åŠ›'
        ]

        # è¶…å£°æ£€æŸ¥ï¼šè¶…å£°ç›¸å…³æ£€æŸ¥æŒ‡æ ‡ï¼ˆç§»é™¤ç–¾ç—…è¯Šæ–­ç›¸å…³è¯æ±‡ï¼Œé¿å…ä¼˜å…ˆçº§å†²çªï¼‰
        ultrasound_keywords = [
            'è¶…å£°', 'Bè¶…', 'å½©è¶…', 'å¤šæ™®å‹’', 'èƒ†ç®¡', 'è‚è„', 'è„¾è„', 'èƒ°è…º', 'è‚¾è„',
            'ä¹³è…º', 'å­å®«', 'é™„ä»¶', 'åµå·¢', 'è†€èƒ±', 'å‰åˆ—è…º', 'ç²¾ç´¢',
            'å¿ƒè„è¶…å£°', 'å¿ƒè„å½©è¶…', 'è¶…å£°å¿ƒåŠ¨å›¾', 'è¡€ç®¡è¶…å£°', 'é¢ˆåŠ¨è„‰', 'ä¸‹è‚¢è¡€ç®¡',
            'èƒå„¿', 'å­•å‘¨', 'ç¾Šæ°´', 'èƒç›˜', 'è„å¸¦', 'å­å®«å†…è†œ', 'åµæ³¡', 'ç›†è…”',
            'è…¹ä¸»åŠ¨è„‰', 'é—¨é™è„‰', 'è„¾é™è„‰', 'è‚é™è„‰', 'ä¸‹è…”é™è„‰', 'è‚¾åŠ¨è„‰',
            'èƒ†å›Šå£', 'èƒ†å›Šç»“çŸ³', 'èƒ†ç»“çŸ³', 'è„‚è‚ªè‚', 'è‚ç¡¬åŒ–', 'è‚å›Šè‚¿',
            'è‚¾å›Šè‚¿', 'è‚¾ç§¯æ°´', 'è„¾å¤§', 'è„¾å¤§', 'å‰åˆ—è…ºå¢ç”Ÿ', 'å‰åˆ—è…ºé’™åŒ–',
            'ä¹³è…ºç»“èŠ‚', 'åµå·¢å›Šè‚¿', 'ç›†è…”ç§¯æ¶²',
            'ç“£è†œ', 'å®¤å£', 'å¿ƒåŠŸèƒ½', 'å°„è¡€åˆ†æ•°', 'å¿ƒåŒ…', 'å¿ƒè‚Œ', 'å† è„‰', 'å† çŠ¶åŠ¨è„‰'
        ]

        # å½±åƒå­¦æ£€æŸ¥ï¼šXå…‰ã€CTã€MRIã€ECTç­‰å½±åƒå­¦æ£€æŸ¥æŒ‡æ ‡
        imaging_keywords = [
            'CT', 'è®¡ç®—æœºæ–­å±‚', 'ç”µå­è®¡ç®—æœºæ–­å±‚', 'èºæ—‹CT', 'å¤šæ’CT',
            'MRI', 'ç£å…±æŒ¯', 'æ ¸ç£å…±æŒ¯', 'åŠŸèƒ½ç£å…±æŒ¯', 'æ‰©æ•£å¼ é‡', 'ç£å…±æŒ¯è¡€ç®¡æˆåƒ',
            'Xå…‰', 'Xå°„çº¿', 'Xçº¿', 'èƒ¸ç‰‡', 'èƒ¸é€', 'è…¹å¹³ç‰‡', 'éª¨éª¼ç‰‡', 'éª¨æŠ˜',
            'PET-CT', 'SPECT', 'ECT', 'éª¨æ‰«æ', 'PET', 'æ­£ç”µå­', 'å•å…‰å­',
            'DSA', 'è¡€ç®¡é€ å½±', 'è„‘è¡€ç®¡é€ å½±', 'å† è„‰é€ å½±', 'ä»‹å…¥',
            'é’¼é¶', 'ä¹³è…ºé’¼é¶', 'é’¡é¤', 'é’¡å‰‚', 'é€ å½±', 'å¢å¼º', 'å¹³æ‰«',
            'è‚ºç»“èŠ‚', 'è‚ºå¤§ç–±', 'è‚ºæ°”è‚¿', 'è‚ºç‚', 'è‚ºçº¤ç»´åŒ–', 'è‚ºç»“æ ¸', 'è‚ºç™Œ',
            'è„‘æ¢—æ­»', 'è„‘å‡ºè¡€', 'è„‘å’ä¸­', 'è„‘èç¼©', 'è„‘ç™½è´¨', 'è„±é«“é˜', 'è„‘è†œç˜¤',
            'è‚è¡€ç®¡ç˜¤', 'è‚ç™Œ', 'è‚è½¬ç§»ç˜¤', 'è„‚è‚ªè‚', 'è‚ç¡¬åŒ–', 'è„¾å¤§', 'èƒ°è…ºç‚',
            'è‚¾ç™Œ', 'è‚¾ç»“çŸ³', 'è‚¾ç§¯æ°´', 'è‚¾å›Šè‚¿', 'è‚¾è¡€ç®¡', 'è‚¾åŠ¨è„‰ç‹­çª„',
            'éª¨è½¬ç§»', 'éª¨è´¨ç–æ¾', 'éª¨è´¨å¢ç”Ÿ', 'æ¤é—´ç›˜', 'æ¤ç®¡ç‹­çª„', 'è„ŠæŸ±ä¾§å¼¯',
            'å† çŠ¶åŠ¨è„‰', 'å† è„‰ç‹­çª„', 'å¿ƒè‚Œç¼ºè¡€', 'å¿ƒè‚Œæ¢—æ­»', 'å¿ƒåŒ…ç§¯æ¶²', 'ä¸»åŠ¨è„‰ç˜¤',
            'æ·‹å·´ç»“', 'çºµéš”', 'èƒ¸è…”ç§¯æ¶²', 'è…¹æ°´', 'è…¹è…”ç§¯æ¶²', 'ç›†è…”ç§¯æ¶²'
        ]

        # ç—…ç—‡è¯Šæ–­ï¼šå„ç§ç–¾ç—…è¯Šæ–­
        diagnosis_keywords = [
            # å¿ƒè¡€ç®¡ç–¾ç—…
            'é«˜è¡€å‹', 'å† å¿ƒç—…', 'å¿ƒç»ç—›', 'å¿ƒè‚Œæ¢—æ­»', 'å¿ƒè‚Œç¼ºè¡€', 'å¿ƒå¾‹å¤±å¸¸', 'å¿ƒè¡°', 'å¿ƒåŠ›è¡°ç«­',
            'é£æ¹¿æ€§å¿ƒè„ç—…', 'å…ˆå¤©æ€§å¿ƒè„ç—…', 'è‚ºå¿ƒç—…', 'å¿ƒåŒ…ç‚', 'å¿ƒè‚Œç‚', 'å¿ƒå†…è†œç‚',
            
            # è„‘è¡€ç®¡ç–¾ç—…
            'è„‘æ¢—æ­»', 'è„‘å‡ºè¡€', 'è„‘å’ä¸­', 'ä¸­é£', 'åå¤´ç—›', 'å¤´ç—›', 'çœ©æ™•', 'å¤´æ™•',
            'ç™«ç—«', 'å¸•é‡‘æ£®ç—…', 'é˜¿å°”èŒ¨æµ·é»˜ç—…', 'è€å¹´ç—´å‘†', 'è„‘ç‚', 'è„‘è†œç‚',
            
            # å‘¼å¸ç³»ç»Ÿç–¾ç—…
            'è‚ºç‚', 'æ”¯æ°”ç®¡ç‚', 'å“®å–˜', 'æ…¢æ€§é˜»å¡æ€§è‚ºç–¾ç—…', 'è‚ºæ°”è‚¿', 'è‚ºç»“æ ¸', 'è‚ºç™Œ',
            'è‚ºæ “å¡', 'è‚ºçº¤ç»´åŒ–', 'è‚ºå¿ƒç—…', 'èƒ¸è†œç‚', 'æ°”èƒ¸', 'å‘¼å¸é“æ„ŸæŸ“',
            
            # æ¶ˆåŒ–ç³»ç»Ÿç–¾ç—…
            'èƒƒç‚', 'èƒƒæºƒç–¡', 'åäºŒæŒ‡è‚ æºƒç–¡', 'ç»“è‚ ç‚', 'å…‹ç½—æ©ç—…', 'æºƒç–¡æ€§ç»“è‚ ç‚',
            'è‚ç‚', 'è‚ç¡¬åŒ–', 'è„‚è‚ªè‚', 'è‚ç™Œ', 'èƒ†å›Šç‚', 'èƒ†ç»“çŸ³', 'èƒ†å›Šæ¯è‚‰', 'èƒ°è…ºç‚', 'èƒ°è…ºç™Œ',
            'é£Ÿç®¡ç‚', 'é£Ÿç®¡ç™Œ', 'èƒƒç™Œ', 'ç»“è‚ ç™Œ', 'ç›´è‚ ç™Œ', 'è‚ æ¢—é˜»', 'é˜‘å°¾ç‚',
            
            # æ³Œå°¿ç³»ç»Ÿç–¾ç—…
            'è‚¾ç‚', 'è‚¾ç—…ç»¼åˆå¾', 'è‚¾è¡°ç«­', 'å°¿æ¯’ç—‡', 'è‚¾ç»“çŸ³', 'è‚¾å›Šè‚¿', 'è‚¾ç™Œ',
            'è†€èƒ±ç‚', 'è†€èƒ±ç™Œ', 'å‰åˆ—è…ºç‚', 'å‰åˆ—è…ºå¢ç”Ÿ', 'å‰åˆ—è…ºç™Œ', 'å°¿è·¯æ„ŸæŸ“',
            
            # å†…åˆ†æ³Œä»£è°¢ç–¾ç—…
            'ç³–å°¿ç—…', 'ç”²çŠ¶è…ºåŠŸèƒ½äº¢è¿›', 'ç”²äº¢', 'ç”²çŠ¶è…ºåŠŸèƒ½å‡é€€', 'ç”²å‡', 'ç”²çŠ¶è…ºç»“èŠ‚',
            'è‚¥èƒ–ç—‡', 'é«˜è¡€è„‚', 'é«˜è„‚è¡€ç—‡', 'ç—›é£', 'éª¨è´¨ç–æ¾', 'ä»£è°¢ç»¼åˆå¾',
            
            # è¡€æ¶²ç³»ç»Ÿç–¾ç—…
            'è´«è¡€', 'ç™½è¡€ç—…', 'æ·‹å·´ç˜¤', 'è¡€å‹ç—…', 'è¡€å°æ¿å‡å°‘ç—‡', 'ç™½ç»†èƒå‡å°‘ç—‡',
            'å†ç”Ÿéšœç¢æ€§è´«è¡€', 'æº¶è¡€æ€§è´«è¡€', 'åœ°ä¸­æµ·è´«è¡€', 'éª¨é«“å¢ç”Ÿå¼‚å¸¸ç»¼åˆå¾',
            
            # é£æ¹¿å…ç–«ç–¾ç—…
            'ç±»é£æ¹¿å…³èŠ‚ç‚', 'ç³»ç»Ÿæ€§çº¢æ–‘ç‹¼ç–®', 'å¼ºç›´æ€§è„ŠæŸ±ç‚', 'ç—›é£', 'éª¨å…³èŠ‚ç‚',
            'é£æ¹¿æ€§å…³èŠ‚ç‚', 'å¹²ç‡¥ç»¼åˆå¾', 'ç¡¬çš®ç—…', 'çš®è‚Œç‚', 'è¡€ç®¡ç‚', 'å…³èŠ‚ç‚',
            
            # ç¥ç»ç³»ç»Ÿç–¾ç—…
            'æŠ‘éƒç—‡', 'ç„¦è™‘ç—‡', 'å¤±çœ ç—‡', 'ç¥ç»è¡°å¼±', 'ä¸‰å‰ç¥ç»ç—›', 'é¢ç¥ç»éº»ç—¹',
            'åéª¨ç¥ç»ç—›', 'é¢ˆæ¤ç—…', 'è…°æ¤é—´ç›˜çªå‡º', 'è…°æ¤ç®¡ç‹­çª„', 'è„Šé«“ç—…å˜',
            
            # å¦‡ç§‘ç–¾ç—…
            'å­å®«è‚Œç˜¤', 'åµå·¢å›Šè‚¿', 'å®«é¢ˆç™Œ', 'å­å®«å†…è†œç™Œ', 'åµå·¢ç™Œ', 'ä¹³è…ºå¢ç”Ÿ',
            'ä¹³è…ºç™Œ', 'å®«é¢ˆç‚', 'é˜´é“ç‚', 'ç›†è…”ç‚', 'å¤šå›Šåµå·¢ç»¼åˆå¾', 'æœˆç»ä¸è°ƒ',
            
            # ç”·æ€§ç–¾ç—…
            'å‰åˆ—è…ºç‚', 'å‰åˆ—è…ºå¢ç”Ÿ', 'å‰åˆ—è…ºç™Œ', 'ç¾ä¸¸ç‚', 'é™„ç¾ç‚', 'é˜³ç—¿', 'æ—©æ³„',
            
            # äº”å®˜ç§‘ç–¾ç—…
            'è¿‘è§†', 'è¿œè§†', 'æ•£å…‰', 'ç™½å†…éšœ', 'é’å…‰çœ¼', 'ç»“è†œç‚', 'è§’è†œç‚', 'é¼»ç‚',
            'é¼»çª¦ç‚', 'å’½ç‚', 'æ‰æ¡ƒä½“ç‚', 'ä¸­è€³ç‚', 'è€³é¸£', 'å¬åŠ›ä¸‹é™',
            
            # çš®è‚¤ç—…
            'æ¹¿ç–¹', 'é“¶å±‘ç—…', 'ç‰›çš®ç™£', 'çš®ç‚', 'è¨éº»ç–¹', 'ç—¤ç–®', 'å¸¦çŠ¶ç–±ç–¹',
            'çš®è‚¤è¿‡æ•', 'ç™½ç™œé£', 'é»„è¤æ–‘', 'çš®è‚¤ç™Œ', 'é»‘è‰²ç´ ç˜¤',
            
            # ä¼ æŸ“ç—…
            'æ„Ÿå†’', 'æµæ„Ÿ', 'ç—…æ¯’æ€§è‚ç‚', 'è‚ºç»“æ ¸', 'è‰¾æ»‹ç—…', 'æ¢…æ¯’', 'æ·‹ç—…', 'å°–é”æ¹¿ç–£',
            
            # å…¶ä»–å¸¸è§ç–¾ç—…
            'å‘çƒ­', 'ç–¼ç—›', 'ç‚ç—‡', 'æ„ŸæŸ“', 'è¿‡æ•', 'ä¸­æ¯’', 'å¤–ä¼¤', 'çƒ§ä¼¤', 'çƒ«ä¼¤'
        ]

        # ç—‡çŠ¶æè¿°ï¼šå„ç§ç—‡çŠ¶è¡¨ç°
        symptoms_keywords = [
            # ä¸€èˆ¬ç—‡çŠ¶
            'å‘çƒ­', 'å¯’æˆ˜', 'ç›—æ±—', 'ä¹åŠ›', 'ç–²å€¦', 'é£Ÿæ¬²ä¸æŒ¯', 'æ¶å¿ƒ', 'å‘•å', 'ä½“é‡ä¸‹é™',
            'ä½“é‡å¢åŠ ', 'æ¶ˆç˜¦', 'è‚¥èƒ–', 'æ°´è‚¿', 'è„±æ°´', 'å£å¹²', 'å£æ¸´',
            
            # å¤´é¢ˆéƒ¨ç—‡çŠ¶
            'å¤´ç—›', 'å¤´æ™•', 'çœ©æ™•', 'å¤±çœ ', 'å—œç¡', 'è®°å¿†åŠ›å‡é€€', 'æ³¨æ„åŠ›ä¸é›†ä¸­',
            'è€³é¸£', 'å¬åŠ›ä¸‹é™', 'è€³ç—›', 'è€³é—·', 'é¼»å¡', 'æµæ¶•', 'é¼»å‡ºè¡€', 'å—…è§‰å‡é€€',
            'å’½ç—›', 'å’½å¼‚ç‰©æ„Ÿ', 'å£°éŸ³å˜¶å“‘', 'å’³å—½', 'å’³ç—°', 'å‘¼å¸å›°éš¾', 'èƒ¸ç—›', 'èƒ¸é—·',
            'å¿ƒæ‚¸', 'å¿ƒæ…Œ', 'æ°”çŸ­', 'å–˜æ¯',
            
            # è…¹éƒ¨ç—‡çŠ¶
            'è…¹ç—›', 'è…¹èƒ€', 'è…¹æ³»', 'ä¾¿ç§˜', 'æ¶å¿ƒ', 'å‘•å', 'åé…¸', 'çƒ§å¿ƒ', 'å—³æ°”',
            'é£Ÿæ¬²å‡é€€', 'åŒé£Ÿ', 'åå’½å›°éš¾', 'æ¶ˆåŒ–ä¸è‰¯', 'èƒƒç—›', 'èƒƒèƒ€', 'è‚åŒºç—›',
            'è…°ç—›', 'è…°é…¸', 'èƒŒç—›', 'èƒç—›',
            
            # æ³Œå°¿ç”Ÿæ®–ç—‡çŠ¶
            'å°¿é¢‘', 'å°¿æ€¥', 'å°¿ç—›', 'å°¿ä¸å°½', 'å°¿å¤±ç¦', 'è¡€å°¿', 'è›‹ç™½å°¿', 'æ°´è‚¿',
            'æ’å°¿å›°éš¾', 'å¤œå°¿å¢å¤š', 'æ€§æ¬²å‡é€€', 'é˜³ç—¿', 'æ—©æ³„', 'æœˆç»ä¸è°ƒ', 'ç—›ç»',
            'ç™½å¸¦å¼‚å¸¸', 'é˜´é“å‡ºè¡€', 'ä¹³æˆ¿èƒ€ç—›', 'ä¹³æˆ¿è‚¿å—',
            
            # ç¥ç»è‚Œè‚‰ç—‡çŠ¶
            'è‚¢ä½“éº»æœ¨', 'è‚Œè‚‰æ— åŠ›', 'è‚Œè‚‰èç¼©', 'è‚Œè‚‰éœ‡é¢¤', 'æŠ½æ', 'ç—‰æŒ›', 'ç–¼ç—›',
            'å…³èŠ‚ç—›', 'å…³èŠ‚è‚¿', 'å…³èŠ‚åƒµç¡¬', 'æ´»åŠ¨å—é™', 'è…°ç—›', 'é¢ˆç—›', 'è‚©ç—›',
            'è‚˜ç—›', 'è…•ç—›', 'é«‹ç—›', 'è†ç—›', 'è¸ç—›', 'è¶³ç—›',
            
            # çš®è‚¤ç—‡çŠ¶
            'çš®ç–¹', 'ç˜™ç—’', 'çº¢æ–‘', 'ä¸˜ç–¹', 'æ°´ç–±', 'è„“ç–±', 'æºƒç–¡', 'ç»“ç—‚',
            'è„±å±‘', 'è‰²ç´ æ²‰ç€', 'è‰²ç´ å‡é€€', 'çš®ä¸‹å‡ºè¡€', 'ç´«ç™œ', 'é»„ç–¸', 'è‹ç™½',
            'å¤šæ±—', 'æ— æ±—', 'å¹²ç‡¥', 'è„±å‘', 'æŒ‡ç”²æ”¹å˜',
            
            # çœ¼éƒ¨ç—‡çŠ¶
            'è§†åŠ›æ¨¡ç³Š', 'è§†åŠ›ä¸‹é™', 'çœ¼ç—›', 'çœ¼å¹²', 'çœ¼ç—’', 'æµæ³ª', 'ç•å…‰', 'å¤è§†',
            'çœ¼çƒçªå‡º', 'çœ¼ç‘è‚¿èƒ€', 'ç»“è†œå……è¡€',
            
            # ç²¾ç¥å¿ƒç†ç—‡çŠ¶
            'ç„¦è™‘', 'æŠ‘éƒ', 'ç´§å¼ ', 'ææƒ§', 'æ˜“æ€’', 'æƒ…ç»ªä½è½', 'å…´è¶£å‡é€€', 'ç¡çœ éšœç¢',
            'å¤šæ¢¦', 'å™©æ¢¦', 'å¥å¿˜', 'æ€ç»´è¿Ÿç¼“', 'æ³¨æ„åŠ›ä¸é›†ä¸­', 'åˆ¤æ–­åŠ›å‡é€€',
            
            # å…¶ä»–ç—‡çŠ¶
            'å‡ºè¡€', 'æ·¤è¡€', 'æ·¤æ–‘', 'è‚¿å—', 'åŒ…å—', 'ç»“èŠ‚', 'å¢ç”Ÿ', 'è‚¥å¤§', 'èç¼©',
            'å˜å½¢', 'ç•¸å½¢', 'ç˜¢ç—•', 'ç˜˜ç®¡', 'çª¦é“'
        ]

        # æ£€æŸ¥å…³é”®è¯æ˜ å°„ï¼ˆåŒ…å«æ–°çš„åˆ†ç±»ï¼‰
        type_mapping = {
            'physical_exam': physical_exam_keywords,
            'blood_routine': blood_routine_keywords,
            'biochemistry': biochemistry_keywords,
            'liver_function': liver_function_keywords,
            'kidney_function': kidney_function_keywords,
            'thyroid_function': thyroid_function_keywords,
            'tumor_markers': tumor_markers_keywords,
            'urine_exam': urine_exam_keywords,
            'blood_rheology': blood_rheology_keywords,
            'eye_exam': eye_exam_keywords,
            'ultrasound_exam': ultrasound_keywords,
            'imaging_exam': imaging_keywords,
            'diagnosis': diagnosis_keywords,
            'symptoms': symptoms_keywords,
        }

        # ä¼˜å…ˆæ£€æŸ¥ç—…ç—‡è¯Šæ–­å’Œç—‡çŠ¶ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        for keyword in diagnosis_keywords:
            if keyword in indicator_name:
                return 'diagnosis'
        
        for keyword in symptoms_keywords:
            if keyword in indicator_name:
                return 'symptoms'

        # ç‰¹æ®Šå¤„ç†ä¸€äº›å¤åˆè¯
        if 'æ”¶ç¼©å‹/èˆ’å¼ å‹' in indicator_name or 'è¡€å‹' in indicator_name:
            return 'physical_exam'  # è¡€å‹å½’ä¸ºä½“æ ¼æ£€æŸ¥
        if 'ä½“é‡æŒ‡æ•°' in indicator_name or 'BMI' in indicator_name:
            return 'physical_exam'

        # ä¼˜å…ˆå¤„ç†è¶…å£°å’Œå½±åƒå­¦æ£€æŸ¥ç›¸å…³çš„ç‰¹æ®Šè¯æ±‡ï¼ˆä¸­ç­‰ä¼˜å…ˆçº§ï¼‰
        ultrasound_patterns = ['è¶…å£°', 'Bè¶…', 'å½©è¶…', 'å¤šæ™®å‹’', 'è¶…å£°å¿ƒåŠ¨å›¾']
        imaging_patterns = ['CT', 'MRI', 'Xå…‰', 'PET', 'SPECT', 'é€ å½±', 'æ–­å±‚', 'ç£å…±æŒ¯']

        for pattern in ultrasound_patterns:
            if pattern in indicator_name:
                return 'ultrasound_exam'

        for pattern in imaging_patterns:
            if pattern in indicator_name:
                return 'imaging_exam'

        # å¤„ç†å™¨å®˜ç›¸å…³çš„æ£€æŸ¥ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼Œåªæœ‰åœ¨æ²¡æœ‰ä»»ä½•å…¶ä»–åŒ¹é…æ—¶æ‰ä½¿ç”¨ï¼‰
        organ_keywords = [
            'è‚è„', 'è„¾è„', 'èƒ°è…º', 'ä¹³è…º', 'å­å®«', 'åµå·¢',
            'å‰åˆ—è…º', 'è†€èƒ±', 'è‚¾è„', 'å¿ƒè„', 'è¡€ç®¡', 'é¢ˆåŠ¨è„‰', 'ä¸‹è‚¢è¡€ç®¡'
            # æ³¨æ„ï¼šç§»é™¤äº†'èƒ†å›Š'å’Œ'ç”²çŠ¶è…º'ï¼Œå› ä¸ºå®ƒä»¬ç»å¸¸ä¸ç–¾ç—…è¯Šæ–­ç»„åˆå‡ºç°
        ]

        # åªæœ‰åœ¨æŒ‡æ ‡åç§°ä¸­ä¸åŒ…å«ä»»ä½•ç–¾ç—…è¯Šæ–­ã€ç—‡çŠ¶ã€æ£€æŸ¥æ–¹æ³•å…³é”®è¯æ—¶ï¼Œæ‰æ ¹æ®å™¨å®˜åç§°æ¨æ–­
        is_organ_only = True
        all_high_priority_keywords = (
            diagnosis_keywords + symptoms_keywords + 
            ultrasound_patterns + imaging_patterns +
            physical_exam_keywords + blood_routine_keywords + 
            biochemistry_keywords + liver_function_keywords +
            kidney_function_keywords + thyroid_function_keywords +
            tumor_markers_keywords + urine_exam_keywords +
            blood_rheology_keywords + eye_exam_keywords
        )
        
        for keyword in all_high_priority_keywords:
            if keyword in indicator_name:
                is_organ_only = False
                break
        
        if is_organ_only:
            for organ in organ_keywords:
                if organ in indicator_name:
                    # å¦‚æœåŒ…å«å½±åƒå­¦å…³é”®è¯ï¼Œåˆ™å½’ä¸ºå½±åƒå­¦ï¼Œå¦åˆ™å½’ä¸ºè¶…å£°
                    for pattern in imaging_patterns:
                        if pattern in indicator_name:
                            return 'imaging_exam'
                    return 'ultrasound_exam'

        # æ¨¡ç³ŠåŒ¹é…å…¶ä»–ç±»å‹ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰
        for indicator_type, keywords in type_mapping.items():
            for keyword in keywords:
                if keyword in indicator_name:
                    return indicator_type

        return 'other_exam'

    def _extract_unit_from_value(self, measured_value, indicator_name):
        """ä»æµ‹é‡å€¼ä¸­æå–å•ä½"""
        import re

        # å¸¸è§å•ä½æ¨¡å¼
        unit_patterns = {
            r'mmHg': 'mmHg',
            r'æ¬¡/åˆ†|bpm|æ¬¡': 'æ¬¡/åˆ†',
            r'mmol/L': 'mmol/L',
            r'kg': 'kg',
            r'cm': 'cm',
            r'Â°C': 'Â°C',
            r'g/L': 'g/L',
            r'Ã—10[^/]/L': 'Ã—10â¹/L',
            r'fl': 'fL',
            r'pg': 'pg',
            r'%': '%'
        }

        # å…ˆä»æµ‹é‡å€¼ä¸­æå–å•ä½
        for pattern, unit in unit_patterns.items():
            if re.search(pattern, measured_value):
                return unit

        # æ ¹æ®æŒ‡æ ‡åç§°æ¨æ–­å•ä½
        if 'è¡€å‹' in indicator_name:
            return 'mmHg'
        elif 'å¿ƒç‡' in indicator_name:
            return 'æ¬¡/åˆ†'
        elif 'è¡€ç³–' in indicator_name or 'èƒ†å›ºé†‡' in indicator_name:
            return 'mmol/L'
        elif 'ä½“é‡' in indicator_name:
            return 'kg'
        elif 'èº«é«˜' in indicator_name:
            return 'cm'
        elif 'ä½“æ¸©' in indicator_name:
            return 'Â°C'

        return ''

    def _clean_measured_value(self, measured_value, unit):
        """æ¸…ç†æµ‹é‡å€¼ï¼Œç§»é™¤å•ä½"""
        if unit:
            # ç§»é™¤å•ä½éƒ¨åˆ†
            import re
            cleaned = re.sub(r'\s*' + re.escape(unit) + r'\s*$', '', str(measured_value))
            return cleaned.strip()
        return str(measured_value).strip()

    def _extract_json_objects(self, text):
        """ä»æ–‡æœ¬ä¸­æå–å®Œæ•´çš„JSONå¯¹è±¡"""
        import json

        json_objects = []
        start_idx = 0

        while start_idx < len(text):
            # æŸ¥æ‰¾ä¸‹ä¸€ä¸ª {
            start_pos = text.find('{', start_idx)
            if start_pos == -1:
                break

            # å¯»æ‰¾åŒ¹é…çš„ }
            brace_count = 0
            end_pos = start_pos

            for i in range(start_pos, len(text)):
                if text[i] == '{':
                    brace_count += 1
                elif text[i] == '}':
                    brace_count -= 1

                if brace_count == 0:
                    end_pos = i
                    break

            # å¦‚æœæ‰¾åˆ°åŒ¹é…çš„æ‹¬å·
            if brace_count == 0:
                json_str = text[start_pos:end_pos + 1]
                # éªŒè¯è¿™æ˜¯å¦æ˜¯æœ‰æ•ˆçš„JSON
                try:
                    parsed = json.loads(json_str)
                    if 'indicators' in parsed:
                        json_objects.append(json_str)
                except json.JSONDecodeError:
                    pass
                start_idx = end_pos + 1
            else:
                start_idx = start_pos + 1

        return json_objects

    def _get_existing_indicator_names(self):
        """è·å–æ•°æ®åº“ä¸­ç°æœ‰çš„æ ‡å‡†æŒ‡æ ‡åç§°"""
        return list(HealthIndicator.objects.values_list('indicator_name', flat=True).distinct().order_by('indicator_name'))

    def _build_llm_prompt(self, ocr_text):
        """æ„å»ºLLMå¤„ç†çš„prompt"""
        # è·å–æ•°æ®åº“ä¸­ç°æœ‰çš„æ ‡å‡†æŒ‡æ ‡åç§°
        existing_indicators = self._get_existing_indicator_names()
        existing_list = '\n'.join([f'  - {name}' for name in existing_indicators])

        return f"""
ä»ä½“æ£€æŠ¥å‘ŠOCRæ–‡æœ¬ä¸­æå–æ‰€æœ‰å¥åº·æŒ‡æ ‡ï¼Œè¿”å›JSONæ ¼å¼ã€‚

æ–‡æœ¬å†…å®¹ï¼š
{ocr_text}

**ä¼˜å…ˆä½¿ç”¨æ ‡å‡†æŒ‡æ ‡åç§°ï¼š**
{existing_list}

**æå–èŒƒå›´ï¼š**
- **æ•°å€¼æŒ‡æ ‡ï¼š** è¡€å‹ã€å¿ƒç‡ã€è¡€ç³–ã€è¡€å¸¸è§„ã€ç”ŸåŒ–æ£€éªŒç­‰å…·ä½“æ•°å€¼
- **è¯Šæ–­ç»“è®ºï¼š** é«˜è¡€å‹ã€ç³–å°¿ç—…ã€è„‚è‚ªè‚ç­‰ç–¾ç—…è¯Šæ–­
- **ç—‡çŠ¶æè¿°ï¼š** å¤´ç—›ã€èƒ¸é—·ã€çš®ç–¹ç­‰ç—‡çŠ¶è¡¨ç°
- **æ£€æŸ¥å‘ç°ï¼š** è¶…å£°ã€CTã€å¿ƒç”µå›¾ç­‰æ£€æŸ¥çš„æè¿°æ€§ç»“æœ
- **ä½“å¾æ•°æ®ï¼š** å™¨å®˜å¤§å°ã€å½¢æ€ç­‰æµ‹é‡å€¼

**ç‰¹åˆ«æ³¨æ„ï¼š**
- ä¸ä»…è¦æå–è¡¨æ ¼æ•°æ®ï¼Œè¿˜è¦è¯†åˆ«æ®µè½ä¸­çš„å¥åº·ä¿¡æ¯
- å¯¹äºæè¿°æ€§æ£€æŸ¥ï¼Œæ¨æ–­å¹¶æå–ç»“æ„åŒ–æŒ‡æ ‡
- ç¡®ä¿ä¸é—æ¼ä»»ä½•æ•°å€¼åŒ–çš„åŒ»å­¦æ£€æŸ¥ç»“æœ

**é‡è¦çº¦æŸï¼š**
1. **ä¸è¦æ— ä¸­ç”Ÿæœ‰ï¼š** åªæå–OCRæ–‡æœ¬ä¸­æ˜ç¡®å­˜åœ¨çš„æŒ‡æ ‡æ•°æ®
2. **å‚è€ƒå€¼å¤„ç†ï¼š** å¦‚æœæŠ¥å‘Šä¸­æ²¡æœ‰æä¾›å‚è€ƒèŒƒå›´ï¼ˆnormal_rangeï¼‰ï¼Œè¯·ç•™ç©ºæˆ–å¡«nullï¼Œä¸è¦ç¼–é€ 
3. **å¼‚å¸¸åˆ¤æ–­ï¼š** åªæœ‰å½“æŠ¥å‘Šä¸­æ˜ç¡®æ ‡æ³¨äº†å¼‚å¸¸ï¼ˆå¦‚â†‘â†“ç®­å¤´ã€å¼‚å¸¸å­—æ ·ã€è¶…å‡ºå‚è€ƒèŒƒå›´ï¼‰æ—¶æ‰æ ‡è®°"æ˜¯"ï¼Œå¦åˆ™ç•™ç©ºæˆ–å¡«null
4. **æ•°æ®çœŸå®æ€§ï¼š** å®å¯å°‘æå–ï¼Œä¹Ÿä¸è¦ç¼–é€ æŠ¥å‘Šä¸­ä¸å­˜åœ¨çš„å†…å®¹

**JSONæ ¼å¼ï¼š**
{{
    "indicators": [
        {{
            "indicator": "æ ‡å‡†åŒ»å­¦æœ¯è¯­",
            "measured_value": "æ£€æµ‹å€¼æˆ–æè¿°",
            "normal_range": "æ­£å¸¸å‚è€ƒèŒƒå›´ï¼ˆå¦‚æœæŠ¥å‘Šä¸­æ²¡æœ‰åˆ™å¡«nullï¼‰",
            "abnormal": "æ˜¯/å¦/nullï¼ˆå¦‚æœæŠ¥å‘Šä¸­æ²¡æœ‰æ˜ç¡®å¼‚å¸¸æ ‡æ³¨åˆ™å¡«nullï¼‰"
        }}
    ]
}}

**ç¤ºä¾‹ï¼š**
- "è¡€å‹ï¼š120/80mmHgï¼ˆæ­£å¸¸90-139/60-89ï¼‰" â†’ {{"indicator": "è¡€å‹", "measured_value": "120/80", "normal_range": "90-139/60-89", "abnormal": "å¦"}}
- "è¯Šæ–­ï¼š2çº§é«˜è¡€å‹" â†’ {{"indicator": "é«˜è¡€å‹", "measured_value": "2çº§", "normal_range": null, "abnormal": "æ˜¯"}}
- "è„¾è„åšåº¦4.5cm" â†’ {{"indicator": "è„¾è„åšåº¦", "measured_value": "4.5cm", "normal_range": null, "abnormal": null}}
- "çº¢ç»†èƒè®¡æ•° 4.5" â†’ {{"indicator": "çº¢ç»†èƒè®¡æ•°", "measured_value": "4.5", "normal_range": null, "abnormal": null}}

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€‚åˆ‡è®°ä¸è¦ç¼–é€ æŠ¥å‘Šä¸­ä¸å­˜åœ¨çš„å‚è€ƒèŒƒå›´å’Œå¼‚å¸¸çŠ¶æ€ã€‚
"""

    def save_health_indicators(self, structured_data):
        """ä¿å­˜å¥åº·æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        try:
            self.update_progress('saving_data', 80, "ä¿å­˜å¥åº·æŒ‡æ ‡æ•°æ®...")

            indicators = structured_data.get('indicators', [])
            saved_count = 0
            skipped_count = 0
            error_count = 0

            for indicator_data in indicators:
                try:
                    # å¤„ç†æ–°çš„LLMå“åº”æ ¼å¼
                    indicator_name = indicator_data.get('indicator', indicator_data.get('name', ''))
                    measured_value = indicator_data.get('measured_value', indicator_data.get('value', ''))
                    normal_range = indicator_data.get('normal_range', indicator_data.get('reference_range', None))
                    is_abnormal = indicator_data.get('abnormal', None)

                    # è·³è¿‡ç¼ºå°‘æŒ‡æ ‡åç§°çš„æ•°æ®
                    if not indicator_name or not str(indicator_name).strip():
                        print(f"âš ï¸  è·³è¿‡æŒ‡æ ‡: ç¼ºå°‘æŒ‡æ ‡åç§°")
                        skipped_count += 1
                        continue

                    # å¤„ç†measured_valueçš„nullå€¼ï¼Œå¢åŠ å®¹é”™æ€§
                    if measured_value is None or measured_value == 'null' or not str(measured_value).strip():
                        clean_value = ''  # ä½¿ç”¨ç©ºå­—ç¬¦ä¸²è€Œä¸æ˜¯'None'
                        print(f"âš ï¸  æŒ‡æ ‡ '{indicator_name}' çš„æ£€æµ‹å€¼ä¸ºç©ºï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²")
                    else:
                        # å¤„ç† null å€¼
                        if normal_range is None or normal_range == 'null':
                            normal_range = ''

                        # è½¬æ¢å¼‚å¸¸çŠ¶æ€
                        if is_abnormal is None or is_abnormal == 'null':
                            # å¦‚æœ LLM æ²¡æœ‰æ˜ç¡®æ ‡æ³¨å¼‚å¸¸ï¼ˆæŠ¥å‘Šä¸­æ²¡æœ‰å‚è€ƒèŒƒå›´ï¼‰ï¼Œåˆ™ä¸åˆ¤æ–­çŠ¶æ€
                            # ç”±äºæ•°æ®åº“å­—æ®µä¸å…è®¸NULLä¸”æœ‰default='normal'ï¼Œè¿™é‡Œç•™ç©ºä¼šä½¿ç”¨é»˜è®¤å€¼
                            status = None  # ä½¿ç”¨æ¨¡å‹é»˜è®¤å€¼
                        elif isinstance(is_abnormal, str):
                            if is_abnormal.lower() in ['æ˜¯', 'yes', 'å¼‚å¸¸', 'true', 'positive', 'é˜³æ€§']:
                                status = 'abnormal'
                            elif is_abnormal.lower() in ['å¦', 'no', 'æ­£å¸¸', 'false', 'negative', 'é˜´æ€§']:
                                status = 'normal'
                            else:
                                # æ— æ³•è¯†åˆ«çš„å­—ç¬¦ä¸²ï¼Œä¸åˆ¤æ–­çŠ¶æ€
                                status = None  # ä½¿ç”¨æ¨¡å‹é»˜è®¤å€¼
                        elif isinstance(is_abnormal, bool):
                            status = 'abnormal' if is_abnormal else 'normal'
                        else:
                            status = None  # ä½¿ç”¨æ¨¡å‹é»˜è®¤å€¼

                        # ç¡®å®šæŒ‡æ ‡ç±»å‹
                        indicator_type = self._get_indicator_type_from_name(indicator_name)

                        # ç¡®å®šå•ä½
                        unit = self._extract_unit_from_value(measured_value, indicator_name)

                        # æ¸…ç†æµ‹é‡å€¼ï¼ˆç§»é™¤å•ä½ï¼‰
                        clean_value = self._clean_measured_value(measured_value, unit)

                    # åˆ›å»ºå¥åº·æŒ‡æ ‡
                    indicator = HealthIndicator.objects.create(
                        checkup=self.document_processing.health_checkup,
                        indicator_type=indicator_type,
                        indicator_name=indicator_name,
                        value=clean_value,
                        unit=unit if unit else '',  # ç¡®ä¿unitä¸æ˜¯None
                        reference_range=normal_range or '',  # ç¡®ä¿ None è½¬ä¸ºç©ºå­—ç¬¦ä¸²
                        status=status if status else 'normal'  # ä¿å­˜è®¡ç®—å‡ºçš„çŠ¶æ€å€¼
                    )
                    saved_count += 1
                    status_display = status if status else 'normal(é»˜è®¤)'
                    print(f"âœ… å·²ä¿å­˜æŒ‡æ ‡ {saved_count}: {indicator_name} = {clean_value if clean_value else '(ç©º)'} {unit if unit else ''} (å‚è€ƒèŒƒå›´:{normal_range or 'ç©º'}, çŠ¶æ€:{status_display})")

                except Exception as e:
                    # å•ä¸ªæŒ‡æ ‡ä¿å­˜å¤±è´¥ä¸å½±å“å…¶ä»–æŒ‡æ ‡
                    error_count += 1
                    print(f"âŒ ä¿å­˜æŒ‡æ ‡å¤±è´¥: {indicator_data.get('indicator', 'æœªçŸ¥æŒ‡æ ‡')} - é”™è¯¯: {str(e)}")
                    continue

            # æ›´æ–°è¿›åº¦
            progress = 80 + int((saved_count / len(indicators)) * 15) if indicators else 95
            summary_msg = f"å·²ä¿å­˜ {saved_count}/{len(indicators)} é¡¹æŒ‡æ ‡"
            if skipped_count > 0:
                summary_msg += f"ï¼Œè·³è¿‡ {skipped_count} é¡¹"
            if error_count > 0:
                summary_msg += f"ï¼Œå¤±è´¥ {error_count} é¡¹"
            self.update_progress('saving_data', progress, summary_msg)

            self.update_progress('completed', 100, f"å¤„ç†å®Œæˆ - æˆåŠŸ:{saved_count}, è·³è¿‡:{skipped_count}, å¤±è´¥:{error_count}")
            return saved_count

        except Exception as e:
            self.update_progress('failed', 0, f"ä¿å­˜æ•°æ®å¤±è´¥: {str(e)}", is_error=True)
            raise

    def process_document(self, file_path):
        """æ‰§è¡Œå®Œæ•´çš„æ–‡æ¡£å¤„ç†æµç¨‹"""
        start_time = datetime.now()

        try:
            workflow_type = self.document_processing.workflow_type

            if workflow_type == 'vl_model':
                # å¤šæ¨¡æ€å¤§æ¨¡å‹å·¥ä½œæµ
                return self._process_with_vl_workflow(file_path, start_time)
            else:
                # ä¼ ç»ŸOCR+LLMå·¥ä½œæµ
                return self._process_with_ocr_llm_workflow(file_path, start_time)

        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

    def _process_with_ocr_llm_workflow(self, file_path, start_time):
        """å¤„ç†OCR+LLMå·¥ä½œæµ"""
        try:
            # 1. OCRè¯†åˆ«
            self.update_progress('uploading', 10, "å¼€å§‹ä¸Šä¼ æ–‡ä»¶...")
            ocr_text = self.perform_ocr(file_path)

            # 2. AIå¤„ç†
            structured_data = self.process_with_llm(ocr_text)

            # 3. ä¿å­˜æ•°æ®
            saved_count = self.save_health_indicators(structured_data)

            # 4. è®¡ç®—å¤„ç†æ—¶é—´
            end_time = datetime.now()
            processing_time = end_time - start_time
            self.document_processing.processing_time = processing_time
            self.document_processing.save()

            return {
                'success': True,
                'indicators_count': saved_count,
                'processing_time': str(processing_time)
            }

        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

    def _process_with_vl_workflow(self, file_path, start_time):
        """å¤„ç†å¤šæ¨¡æ€å¤§æ¨¡å‹å·¥ä½œæµ"""
        try:
            # ä½¿ç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹æœåŠ¡
            vl_service = VisionLanguageModelService(self.document_processing)

            # 1. å¤šæ¨¡æ€å¤§æ¨¡å‹å¤„ç†
            self.update_progress('uploading', 10, "å‡†å¤‡å¤šæ¨¡æ€åˆ†æ...")
            structured_data = vl_service.process_with_vision_model(file_path)

            # 2. ä¿å­˜æ•°æ®
            saved_count = vl_service.save_vision_indicators(structured_data)

            # 3. è®¡ç®—å¤„ç†æ—¶é—´
            end_time = datetime.now()
            processing_time = end_time - start_time
            self.document_processing.processing_time = processing_time
            self.document_processing.save()

            return {
                'success': True,
                'indicators_count': saved_count,
                'processing_time': str(processing_time)
            }

        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }


def get_mineru_api_status():
    """æ£€æŸ¥MinerU APIçŠ¶æ€"""
    try:
        # ä»æ•°æ®åº“è·å–é…ç½®
        mineru_api_url = SystemSettings.get_setting('mineru_api_url', 'http://localhost:8000')
        response = requests.get(f"{mineru_api_url}/docs", timeout=5)
        return response.status_code == 200
    except:
        return False


def get_llm_api_status():
    """æ£€æŸ¥LLM APIçŠ¶æ€"""
    try:
        # ä»æ•°æ®åº“è·å–é…ç½®
        llm_config = SystemSettings.get_llm_config()
        llm_provider = llm_config.get('provider', 'openai')
        llm_api_url = llm_config.get('api_url')
        llm_api_key = llm_config.get('api_key')
        llm_model_name = llm_config.get('model_name')

        if not llm_api_url or not llm_model_name:
            return False

        # å‘é€æµ‹è¯•è¯·æ±‚
        if llm_provider == 'gemini':
            # Gemini API
            gemini_api_key = SystemSettings.get_setting('gemini_api_key', '')
            if not gemini_api_key:
                return False

            check_url = f"https://generativelanguage.googleapis.com/v1beta/models/{llm_model_name}:generateContent?key={gemini_api_key}"
            data = {"contents": [{"parts": [{"text": "test"}]}]}
        else:
            # OpenAIå…¼å®¹æ ¼å¼ - ç›´æ¥ä½¿ç”¨é…ç½®çš„API URL
            check_url = llm_api_url
            data = {
                "model": llm_model_name,
                "messages": [{"role": "user", "content": "test"}],
                "max_tokens": 5
            }

        headers = {'Content-Type': 'application/json'}
        if llm_api_key:
            headers['Authorization'] = f"Bearer {llm_api_key}"

        response = requests.post(check_url, json=data, headers=headers, timeout=10)
        return response.status_code == 200
    except:
        return False


class VisionLanguageModelService:
    """å¤šæ¨¡æ€å¤§æ¨¡å‹æœåŠ¡ç±»"""

    def __init__(self, document_processing):
        self.document_processing = document_processing
        # è·å–å¤šæ¨¡æ€æ¨¡å‹é…ç½®
        config = SystemSettings.get_vl_model_config()
        self.vl_provider = config['provider']
        self.vl_api_url = config['api_url']
        self.vl_api_key = config['api_key']
        self.vl_model_name = config['model_name']
        self.vl_timeout = int(config['timeout'])
        self.vl_max_tokens = int(config['max_tokens'])

    def update_progress(self, status, progress, message=None, is_error=False):
        """æ›´æ–°å¤„ç†è¿›åº¦"""
        self.document_processing.status = status
        self.document_processing.progress = progress
        if message and is_error:
            self.document_processing.error_message = message
        elif message and not is_error:
            self.document_processing.error_message = None
        self.document_processing.save()

    def process_with_vision_model(self, file_path):
        """ä½¿ç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹ç›´æ¥å¤„ç†æ–‡æ¡£å›¾ç‰‡"""
        try:
            print(f"\n{'='*80}")
            print(f"ğŸ¤– [å¤šæ¨¡æ€å¤§æ¨¡å‹] å¼€å§‹å¤„ç†æ–‡æ¡£")
            print(f"ğŸ“„ æ–‡ä»¶è·¯å¾„: {file_path}")
            print(f"â° å¤„ç†å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

            self.update_progress('ai_processing', 30, "å¼€å§‹å¤šæ¨¡æ€å¤§æ¨¡å‹åˆ†æ...")

            # åˆ¤æ–­æ–‡ä»¶ç±»å‹
            file_ext = file_path.lower().split('.')[-1] if '.' in file_path.lower() else 'unknown'
            print(f"ğŸ“‹ æ£€æµ‹åˆ°æ–‡ä»¶ç±»å‹: {file_ext}")

            if file_path.lower().endswith('.pdf'):
                # PDFæ–‡ä»¶éœ€è¦è½¬æ¢ä¸ºå›¾ç‰‡
                print(f"ğŸ”„ PDFæ–‡ä»¶éœ€è¦è½¬æ¢ä¸ºå›¾ç‰‡...")
                try:
                    images = self._convert_pdf_to_images(file_path)
                    print(f"âœ… PDFè½¬æ¢æˆåŠŸï¼Œå…±{len(images)}é¡µ")
                    self.update_progress('ai_processing', 40, f"PDFè½¬æ¢æˆåŠŸï¼Œå…±{len(images)}é¡µ")
                except Exception as pdf_error:
                    # å¦‚æœPDFè½¬æ¢å¤±è´¥ï¼Œå»ºè®®ç”¨æˆ·ä½¿ç”¨å…¶ä»–å·¥ä½œæµ
                    print(f"âŒ PDFè½¬æ¢å¤±è´¥: {str(pdf_error)}")
                    error_msg = f"PDFæ–‡ä»¶å¤„ç†å¤±è´¥ï¼š{str(pdf_error)}\n\nå»ºè®®ï¼š\n1. å¯¹äºPDFæ–‡ä»¶ï¼Œå»ºè®®ä½¿ç”¨'MinerU Pipeline'æˆ–'MinerU VLM-Transformers'å·¥ä½œæµ\n2. æˆ–è€…å°†PDFè½¬æ¢ä¸ºå›¾ç‰‡åä½¿ç”¨å¤šæ¨¡æ€å·¥ä½œæµ\n3. æˆ–è€…å®‰è£…popplerä¾èµ–ä»¥æ”¯æŒPDFè½¬æ¢"
                    self.update_progress('failed', 0, error_msg, is_error=True)
                    raise Exception(error_msg)
            else:
                # å›¾ç‰‡æ–‡ä»¶ç›´æ¥å¤„ç†
                images = [file_path]
                print(f"ğŸ–¼ï¸  æ£€æµ‹åˆ°å›¾ç‰‡æ–‡ä»¶ï¼Œç›´æ¥å¤„ç†")
                self.update_progress('ai_processing', 40, "æ£€æµ‹åˆ°å›¾ç‰‡æ–‡ä»¶ï¼Œç›´æ¥å¤„ç†")

            all_indicators = []
            total_images = len(images)
            print(f"ğŸ“Š æ€»å…±éœ€è¦å¤„ç† {total_images} é¡µ/å¼ å›¾ç‰‡")

            for i, image_path in enumerate(images):
                progress = 40 + int((i / total_images) * 30)
                self.update_progress('ai_processing', progress, f"åˆ†æç¬¬ {i+1}/{total_images} é¡µ...")

                # å¤„ç†å•é¡µå›¾ç‰‡
                indicators = self._process_single_image(image_path, i+1, total_images)
                all_indicators.extend(indicators)
                print(f"ğŸ“ˆ ç¬¬ {i+1} é¡µå¤„ç†å®Œæˆï¼Œæå–åˆ° {len(indicators)} ä¸ªæŒ‡æ ‡")

            print(f"ğŸ“‹ æ‰€æœ‰é¡µé¢å¤„ç†å®Œæˆï¼ŒåŸå§‹æŒ‡æ ‡æ€»æ•°: {len(all_indicators)}")

            # åˆå¹¶å’Œå»é‡æŒ‡æ ‡
            print(f"ğŸ”„ å¼€å§‹åˆå¹¶å’Œå»é‡æŒ‡æ ‡...")
            unique_indicators = self._merge_indicators(all_indicators)
            print(f"ğŸ“Š å»é‡åæŒ‡æ ‡æ€»æ•°: {len(unique_indicators)}")

            # ä¿å­˜å¤„ç†ç»“æœ
            processing_result = {
                'indicators': unique_indicators,
                'total_pages': total_images,
                'file_type': 'PDF' if file_path.lower().endswith('.pdf') else 'Image',
                'processing_time': datetime.now().isoformat()
            }

            self.document_processing.vl_model_result = processing_result
            self.document_processing.save()

            print(f"ğŸ’¾ å¤„ç†ç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“")
            print(f"â° å¤„ç†å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"ğŸ‰ å¤šæ¨¡æ€å¤§æ¨¡å‹å¤„ç†å®Œæˆ!")
            print(f"{'='*80}\n")

            self.update_progress('ai_processing', 70, "å¤šæ¨¡æ€å¤§æ¨¡å‹åˆ†æå®Œæˆ")
            return {
                'indicators': unique_indicators,
                'total_pages': total_images
            }

        except Exception as e:
            print(f"âŒ å¤šæ¨¡æ€å¤§æ¨¡å‹å¤„ç†å¤±è´¥: {str(e)}")
            print(f"â° å¤±è´¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"{'='*80}\n")
            self.update_progress('failed', 0, f"å¤šæ¨¡æ€å¤§æ¨¡å‹å¤„ç†å¤±è´¥: {str(e)}", is_error=True)
            raise

    def _convert_pdf_to_images(self, pdf_path):
        """å°†PDFè½¬æ¢ä¸ºå›¾ç‰‡"""
        try:
            from pdf2image import convert_from_path
            import tempfile
            import os
            
            # å°è¯•ä½¿ç”¨popplerè·¯å¾„ï¼ˆWindowså¸¸è§è·¯å¾„ï¼‰
            poppler_path = None
            if os.name == 'nt':  # Windowsç³»ç»Ÿ
                # å¸¸è§çš„popplerå®‰è£…è·¯å¾„
                possible_paths = [
                    r"C:\Program Files\poppler-23\bin",
                    r"C:\Program Files\poppler-22\bin", 
                    r"C:\Program Files\poppler\bin",
                    r"C:\Program Files (x86)\poppler-23\bin",
                    r"C:\Program Files (x86)\poppler-22\bin",
                    r"C:\Program Files (x86)\poppler\bin",
                    r"C:\poppler\bin",
                    r"C:\tools\poppler\bin",
                ]
                
                for path in possible_paths:
                    if os.path.exists(path):
                        poppler_path = path
                        break
                
                # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–
                if not poppler_path:
                    poppler_path = os.environ.get('POPPLER_BIN_PATH')
            
            # è½¬æ¢PDFä¸ºå›¾ç‰‡
            try:
                if poppler_path:
                    images = convert_from_path(pdf_path, dpi=200, fmt='jpeg', poppler_path=poppler_path)
                else:
                    images = convert_from_path(pdf_path, dpi=200, fmt='jpeg')
            except Exception as e:
                if "poppler" in str(e).lower() or "Unable to get page count" in str(e):
                    # å¦‚æœæ˜¯popplerç›¸å…³é”™è¯¯ï¼Œæä¾›å¤‡é€‰æ–¹æ¡ˆ
                    raise Exception(f"PDFè½¬å›¾ç‰‡å¤±è´¥ï¼šç³»ç»Ÿç¼ºå°‘popplerä¾èµ–ã€‚è¯·å®‰è£…poppleræˆ–ä½¿ç”¨å…¶ä»–å·¥ä½œæµã€‚\nè¯¦ç»†é”™è¯¯: {str(e)}\n\nå»ºè®®è§£å†³æ–¹æ¡ˆï¼š\n1. ä¸‹è½½å¹¶å®‰è£…poppler for Windows\n2. è®¾ç½®POPPLER_BIN_PATHç¯å¢ƒå˜é‡æŒ‡å‘poppler/binç›®å½•\n3. æˆ–è€…ä½¿ç”¨'MinerU Pipeline'æˆ–'MinerU VLM-Transformers'å·¥ä½œæµå¤„ç†PDFæ–‡ä»¶")
                else:
                    raise e

            # åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜å›¾ç‰‡
            temp_dir = tempfile.mkdtemp()
            temp_image_paths = []
            
            for i, image in enumerate(images):
                temp_path = os.path.join(temp_dir, f"pdf_page_{i}.jpg")
                image.save(temp_path, 'JPEG')
                temp_image_paths.append(temp_path)

            return temp_image_paths
            
        except ImportError:
            raise Exception("éœ€è¦å®‰è£…pdf2imageåº“: pip install pdf2image")
        except Exception as e:
            if "poppler" in str(e).lower():
                raise Exception(f"PDFè½¬å›¾ç‰‡å¤±è´¥ï¼šç³»ç»Ÿç¼ºå°‘popplerä¾èµ–ã€‚è¯·å®‰è£…poppleræˆ–ä½¿ç”¨å…¶ä»–å·¥ä½œæµå¤„ç†PDFæ–‡ä»¶ã€‚\nè¯¦ç»†é”™è¯¯: {str(e)}\n\nå»ºè®®è§£å†³æ–¹æ¡ˆï¼š\n1. ä¸‹è½½å¹¶å®‰è£…poppler for Windows\n2. è®¾ç½®POPPLER_BIN_PATHç¯å¢ƒå˜é‡æŒ‡å‘poppler/binç›®å½•\n3. æˆ–è€…ä½¿ç”¨'MinerU Pipeline'æˆ–'MinerU VLM-Transformers'å·¥ä½œæµå¤„ç†PDFæ–‡ä»¶")
            else:
                raise Exception(f"PDFè½¬å›¾ç‰‡å¤±è´¥: {str(e)}")

    def _process_single_image(self, image_path, page_num, total_pages):
        """å¤„ç†å•é¡µå›¾ç‰‡"""
        try:
            print(f"\n{'='*60}")
            print(f"ğŸ” [å¤šæ¨¡æ€å¤§æ¨¡å‹] å¼€å§‹å¤„ç†ç¬¬ {page_num}/{total_pages} é¡µå›¾ç‰‡")
            print(f"ğŸ“ å›¾ç‰‡è·¯å¾„: {image_path}")

            # æ„å»ºé’ˆå¯¹åŒ»ç–—æŠ¥å‘Šçš„prompt
            prompt = self._build_vision_prompt(page_num, total_pages)
            print(f"ğŸ“ Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")
            print(f"ğŸ“ Promptå‰200å­—ç¬¦: {prompt[:200]}...")

            # æ ¹æ®æä¾›å•†é€‰æ‹©ä¸åŒçš„APIè°ƒç”¨æ–¹å¼
            if self.vl_provider == 'gemini':
                # ä½¿ç”¨ Gemini Vision API
                return self._call_gemini_vision_api(image_path, prompt)
            else:
                # ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼
                return self._call_openai_vision_api(image_path, prompt)

        except Exception as e:
            print(f"âŒ å¤„ç†ç¬¬{page_num}é¡µå›¾ç‰‡å¤±è´¥: {str(e)}")
            print(f"{'='*60}\n")
            return []

    def _call_gemini_vision_api(self, image_path, prompt):
        """è°ƒç”¨ Gemini Vision API"""
        try:
            # æ£€æŸ¥ Gemini API Key
            gemini_api_key = SystemSettings.get_setting('gemini_api_key')
            if not gemini_api_key:
                raise Exception("æœªé…ç½®Gemini APIå¯†é’¥ï¼Œè¯·åœ¨ç³»ç»Ÿè®¾ç½®ä¸­é…ç½®")

            # ä½¿ç”¨ Gemini æ¨¡å‹åç§°æˆ–é…ç½®çš„å¤šæ¨¡æ€æ¨¡å‹åç§°
            model_name = SystemSettings.get_setting('gemini_model_name', self.vl_model_name)

            # è¯»å–å¹¶ç¼–ç å›¾ç‰‡
            with open(image_path, 'rb') as f:
                image_data = base64.b64encode(f.read()).decode('utf-8')

            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "contents": [{
                    "parts": [
                        {
                            "inline_data": {
                                "mime_type": "image/jpeg",
                                "data": image_data
                            }
                        },
                        {
                            "text": prompt
                        }
                    ]
                }],
                "generationConfig": {
                    "temperature": 0.1,
                    "maxOutputTokens": self.vl_max_tokens
                }
            }

            # æ„å»ºAPI URL
            api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={gemini_api_key}"

            print(f"ğŸŒ Gemini APIé…ç½®ä¿¡æ¯:")
            print(f"   - API URL: {api_url}")
            print(f"   - æ¨¡å‹åç§°: {model_name}")
            print(f"   - è¶…æ—¶æ—¶é—´: {self.vl_timeout}ç§’")
            print(f"ğŸ“¤ è¯·æ±‚æ•°æ®å¤§å°: {len(json.dumps(request_data))} å­—ç¬¦")

            # è®°å½•è¯·æ±‚å¼€å§‹æ—¶é—´
            import time
            start_time = time.time()

            print(f"ğŸš€ æ­£åœ¨å‘é€è¯·æ±‚åˆ° Gemini...")
            response = requests.post(
                api_url,
                json=request_data,
                headers={"Content-Type": "application/json"},
                timeout=self.vl_timeout
            )

            # è®¡ç®—è¯·æ±‚è€—æ—¶
            end_time = time.time()
            request_duration = end_time - start_time
            print(f"â±ï¸  è¯·æ±‚è€—æ—¶: {request_duration:.2f} ç§’")
            print(f"ğŸ“¥ å“åº”çŠ¶æ€ç : {response.status_code}")
            print(f"ğŸ“¥ å“åº”å¤§å°: {len(response.text)} å­—ç¬¦")
            print(f"ğŸ“¥ å“åº”å‰500å­—ç¬¦: {response.text[:500]}...")

            if response.status_code == 200:
                result = response.json()
                content = result['candidates'][0]['content']['parts'][0]['text']

                print(f"âœ… Gemini APIè°ƒç”¨æˆåŠŸ!")
                print(f"ğŸ“„ è¿”å›å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                print(f"ğŸ“„ è¿”å›å†…å®¹å‰300å­—ç¬¦: {content[:300]}...")

                # è§£æè¿”å›çš„JSONç»“æœ
                print(f"ğŸ”§ å¼€å§‹è§£æJSONå“åº”...")
                indicators = self._parse_vision_response(content)

                print(f"ğŸ“Š è§£æå®Œæˆï¼Œæå–åˆ° {len(indicators)} ä¸ªæŒ‡æ ‡")
                for i, indicator in enumerate(indicators):
                    print(f"   æŒ‡æ ‡ {i+1}: {indicator.get('indicator', 'N/A')} = {indicator.get('measured_value', 'N/A')} ({indicator.get('abnormal', 'N/A')})")

                print(f"{'='*60}\n")
                return indicators
            else:
                print(f"âŒ Gemini APIè°ƒç”¨å¤±è´¥!")
                print(f"âŒ é”™è¯¯è¯¦æƒ…: {response.text}")
                raise Exception(f"Gemini APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")

        except Exception as e:
            print(f"âŒ Gemini Vision APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise

    def _call_openai_vision_api(self, image_path, prompt):
        """è°ƒç”¨ OpenAI å…¼å®¹æ ¼å¼çš„ Vision API"""
        try:
            # å‡†å¤‡è¯·æ±‚æ•°æ®
            request_data = {
                "model": self.vl_model_name,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œä¸“é—¨ä»ä½“æ£€æŠ¥å‘Šå›¾ç‰‡ä¸­æå–å¥åº·æŒ‡æ ‡æ•°æ®ã€‚"
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": self._encode_image_to_base64(image_path),
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                "temperature": 0.1,
                "max_tokens": self.vl_max_tokens
            }

            # å‡†å¤‡è¯·æ±‚å¤´
            headers = {
                "Content-Type": "application/json"
            }

            if self.vl_api_key:
                headers["Authorization"] = f"Bearer {self.vl_api_key}"

            # APIè°ƒç”¨ç›´æ¥ä½¿ç”¨é…ç½®çš„å®Œæ•´åœ°å€
            api_url = self.vl_api_url

            print(f"ğŸŒ OpenAI Vision APIé…ç½®ä¿¡æ¯:")
            print(f"   - API URL: {api_url}")
            print(f"   - æ¨¡å‹åç§°: {self.vl_model_name}")
            print(f"   - è¶…æ—¶æ—¶é—´: {self.vl_timeout}ç§’")
            print(f"   - æœ€å¤§ä»¤ç‰Œæ•°: {self.vl_max_tokens}")
            print(f"   - API Key: {'å·²è®¾ç½®' if self.vl_api_key else 'æœªè®¾ç½®'}")
            print(f"ğŸ“¤ è¯·æ±‚æ•°æ®å¤§å°: {len(json.dumps(request_data))} å­—ç¬¦")

            # è®°å½•è¯·æ±‚å¼€å§‹æ—¶é—´
            import time
            start_time = time.time()

            print(f"ğŸš€ æ­£åœ¨å‘é€è¯·æ±‚åˆ°å¤šæ¨¡æ€å¤§æ¨¡å‹...")
            response = requests.post(
                api_url,
                json=request_data,
                headers=headers,
                timeout=self.vl_timeout
            )

            # è®¡ç®—è¯·æ±‚è€—æ—¶
            end_time = time.time()
            request_duration = end_time - start_time
            print(f"â±ï¸  è¯·æ±‚è€—æ—¶: {request_duration:.2f} ç§’")
            print(f"ğŸ“¥ å“åº”çŠ¶æ€ç : {response.status_code}")
            print(f"ğŸ“¥ å“åº”å¤§å°: {len(response.text)} å­—ç¬¦")
            print(f"ğŸ“¥ å“åº”å‰500å­—ç¬¦: {response.text[:500]}...")

            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']

                print(f"âœ… APIè°ƒç”¨æˆåŠŸ!")
                print(f"ğŸ“„ è¿”å›å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                print(f"ğŸ“„ è¿”å›å†…å®¹å‰300å­—ç¬¦: {content[:300]}...")

                # è§£æè¿”å›çš„JSONç»“æœ
                print(f"ğŸ”§ å¼€å§‹è§£æJSONå“åº”...")
                indicators = self._parse_vision_response(content)

                print(f"ğŸ“Š è§£æå®Œæˆï¼Œæå–åˆ° {len(indicators)} ä¸ªæŒ‡æ ‡")
                for i, indicator in enumerate(indicators):
                    print(f"   æŒ‡æ ‡ {i+1}: {indicator.get('indicator', 'N/A')} = {indicator.get('measured_value', 'N/A')} ({indicator.get('abnormal', 'N/A')})")

                print(f"{'='*60}\n")
                return indicators
            else:
                print(f"âŒ APIè°ƒç”¨å¤±è´¥!")
                print(f"âŒ é”™è¯¯è¯¦æƒ…: {response.text}")
                raise Exception(f"å¤šæ¨¡æ€æ¨¡å‹APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")

        except Exception as e:
            print(f"âŒ OpenAI Vision APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise

    def _encode_image_to_base64(self, image_path):
        """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64"""
        import base64

        # è¯»å–å›¾ç‰‡å¹¶è°ƒæ•´å¤§å°ï¼ˆå¦‚æœå¤ªå¤§ï¼‰
        from PIL import Image
        import io

        with Image.open(image_path) as img:
            # é™åˆ¶æœ€å¤§å°ºå¯¸ä¸º1024x1024
            max_size = 1024
            if img.width > max_size or img.height > max_size:
                img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)

            # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆå¦‚æœä¸æ˜¯ï¼‰
            if img.mode != 'RGB':
                img = img.convert('RGB')

            # ä¿å­˜åˆ°å†…å­˜
            buffer = io.BytesIO()
            img.save(buffer, format='JPEG', quality=85)
            buffer.seek(0)

            # ç¼–ç ä¸ºbase64
            image_data = buffer.read()
            base64_data = base64.b64encode(image_data).decode('utf-8')

        return f"data:image/jpeg;base64,{base64_data}"

    def _build_vision_prompt(self, page_num, total_pages):
        """æ„å»ºè§†è§‰æ¨¡å‹çš„prompt"""
        return f"""
åˆ†æç¬¬{page_num}/{total_pages}é¡µåŒ»ç–—å›¾ç‰‡ï¼Œæå–æ‰€æœ‰å¥åº·ç›¸å…³ä¿¡æ¯ã€‚

**ä»»åŠ¡è¦æ±‚ï¼š**
1. **ä½“æ£€æŠ¥å‘Šï¼š** è¯†åˆ«å¹¶æå–æ‰€æœ‰åŒ»å­¦æ£€æŸ¥ç»“æœã€æŒ‡æ ‡æ•°æ®ã€è¯Šæ–­ç»“è®º
2. **ç—‡çŠ¶ç…§ç‰‡ï¼š** è¯¦ç»†æè¿°å¯è§çš„ç—‡çŠ¶è¡¨ç°ã€ä½“å¾ç‰¹å¾

**æå–é‡ç‚¹ï¼š**
- **æ•°å€¼æŒ‡æ ‡ï¼š** è¡€å‹ã€å¿ƒç‡ã€è¡€ç³–ã€è¡€å¸¸è§„ã€ç”ŸåŒ–æ£€éªŒç­‰å…·ä½“æ£€æµ‹æ•°å€¼
- **è¯Šæ–­ç»“è®ºï¼š** å¦‚"é«˜è¡€å‹"ã€"ç³–å°¿ç—…"ã€"è„‚è‚ªè‚"ç­‰ç–¾ç—…è¯Šæ–­
- **ç—‡çŠ¶æè¿°ï¼š** å¦‚"å¤´ç—›"ã€"çš®ç–¹"ã€"çº¢è‚¿"ç­‰å…·ä½“ç—‡çŠ¶è¡¨ç°
- **æ£€æŸ¥å‘ç°ï¼š** è¶…å£°ã€CTã€Xå…‰ç­‰å½±åƒå­¦æ£€æŸ¥çš„æè¿°æ€§ç»“æœ
- **ä½“å¾æ•°æ®ï¼š** å™¨å®˜å¤§å°ã€åšåº¦ã€å½¢æ€ç­‰è§£å‰–ç»“æ„æµ‹é‡å€¼

**é‡è¦çº¦æŸï¼š**
1. **ä¸è¦æ— ä¸­ç”Ÿæœ‰ï¼š** åªæå–å›¾ç‰‡ä¸­æ˜ç¡®å¯è§æˆ–æ˜ç¡®å†™æ˜çš„æŒ‡æ ‡æ•°æ®
2. **å‚è€ƒå€¼å¤„ç†ï¼š** å¦‚æœå›¾ç‰‡ä¸­æ²¡æœ‰æä¾›å‚è€ƒèŒƒå›´ï¼ˆnormal_rangeï¼‰ï¼Œè¯·ç•™ç©ºæˆ–å¡«nullï¼Œä¸è¦ç¼–é€ 
3. **å¼‚å¸¸åˆ¤æ–­ï¼š** åªæœ‰å½“å›¾ç‰‡ä¸­æ˜ç¡®æ ‡æ³¨äº†å¼‚å¸¸ï¼ˆå¦‚â†‘â†“ç®­å¤´ã€å¼‚å¸¸å­—æ ·ã€è¶…å‡ºå‚è€ƒèŒƒå›´ã€é˜³æ€§ï¼‰æ—¶æ‰æ ‡è®°"æ˜¯"ï¼Œå¦åˆ™ç•™ç©ºæˆ–å¡«null
4. **æ•°æ®çœŸå®æ€§ï¼š** å®å¯å°‘æå–ï¼Œä¹Ÿä¸è¦ç¼–é€ å›¾ç‰‡ä¸­ä¸å­˜åœ¨çš„å†…å®¹
5. **æ¸…æ™°åº¦è¦æ±‚ï¼š** å¦‚æœæ–‡å­—æ¨¡ç³Šä¸æ¸…æ— æ³•å‡†ç¡®è¯†åˆ«ï¼Œä¸è¦å¼ºè¡ŒçŒœæµ‹ï¼Œåº”è¯¥ç•¥è¿‡è¯¥é¡¹æ•°æ®

**JSONæ ¼å¼è¦æ±‚ï¼š**
{{
    "indicators": [
        {{
            "indicator": "æ ‡å‡†åŒ»å­¦æœ¯è¯­åç§°",
            "measured_value": "æ£€æµ‹å€¼æˆ–ç—‡çŠ¶æè¿°",
            "normal_range": "æ­£å¸¸å‚è€ƒèŒƒå›´ï¼ˆå¦‚æœå›¾ç‰‡ä¸­æ²¡æœ‰åˆ™å¡«nullï¼‰",
            "abnormal": "æ˜¯/å¦/nullï¼ˆå¦‚æœå›¾ç‰‡ä¸­æ²¡æœ‰æ˜ç¡®å¼‚å¸¸æ ‡æ³¨åˆ™å¡«nullï¼‰"
        }}
    ]
}}

**ç¤ºä¾‹ï¼š**
- è¡€å‹"120/80" â†’ {{"indicator": "è¡€å‹", "measured_value": "120/80", "normal_range": "90-140/60-90", "abnormal": "å¦"}}
- è¯Šæ–­"é«˜è¡€å‹2çº§" â†’ {{"indicator": "é«˜è¡€å‹", "measured_value": "2çº§", "normal_range": null, "abnormal": "æ˜¯"}}
- ç—‡çŠ¶"çš®è‚¤çº¢ç–¹" â†’ {{"indicator": "çš®è‚¤çš®ç–¹", "measured_value": "çº¢è‰²ä¸˜ç–¹", "normal_range": null, "abnormal": "æ˜¯"}}
- çº¢ç»†èƒè®¡æ•°"4.5" â†’ {{"indicator": "çº¢ç»†èƒè®¡æ•°", "measured_value": "4.5", "normal_range": null, "abnormal": null}}

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—ã€‚åˆ‡è®°ä¸è¦ç¼–é€ å›¾ç‰‡ä¸­ä¸å­˜åœ¨çš„å‚è€ƒèŒƒå›´å’Œå¼‚å¸¸çŠ¶æ€ã€‚
"""

    def _extract_json_from_text(self, text):
        """æ™ºèƒ½æå–å’Œæ¸…ç†JSONå†…å®¹"""
        print(f"ğŸ”§ å¼€å§‹æ™ºèƒ½JSONæå–å’Œæ¸…ç†...")
        print(f"ğŸ“„ åŸå§‹æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        print(f"ğŸ“„ åŸå§‹æ–‡æœ¬å‰300å­—ç¬¦: {text[:300]}...")

        # æ–¹æ³•1: å°è¯•ç›´æ¥è§£æï¼ˆå¦‚æœæ–‡æœ¬æœ¬èº«å°±æ˜¯çº¯å‡€çš„JSONï¼‰
        try:
            result = json.loads(text.strip())
            print(f"âœ… æ–¹æ³•1æˆåŠŸ: ç›´æ¥è§£æJSON")
            return result
        except json.JSONDecodeError:
            print(f"âŒ æ–¹æ³•1å¤±è´¥: æ— æ³•ç›´æ¥è§£æJSON")

        # æ–¹æ³•2: æ¸…ç†å¸¸è§çš„ä»£ç å—æ ‡è®°
        cleaned_patterns = [
            # ç§»é™¤ä»£ç å—æ ‡è®°
            (r'```json\s*', ''),
            (r'```\s*', ''),
            # ç§»é™¤å¯èƒ½çš„å‰å¯¼æ–‡å­—è¯´æ˜
            (r'^.*?(?=\s*\{)', '', re.DOTALL),
            # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–‡å­—è¯´æ˜
            (r'\}[^}]*$', '}'),
            # ç§»é™¤å¸¸è§çš„å‰ç¼€æ–‡å­—
            (r'^(?:ä»¥ä¸‹æ˜¯|Here is|The result is|è¾“å‡º|è¿”å›|Result)[:ï¼š\s]*', '', re.IGNORECASE),
        ]

        cleaned_text = text
        for pattern, replacement, *flags in cleaned_patterns:
            flags = flags[0] if flags else 0
            old_text = cleaned_text
            cleaned_text = re.sub(pattern, replacement, cleaned_text, flags=flags)
            if old_text != cleaned_text:
                print(f"ğŸ§¹ æ¸…ç†æ¨¡å¼åº”ç”¨: ç§»é™¤äº† {len(old_text) - len(cleaned_text)} ä¸ªå­—ç¬¦")

        cleaned_text = cleaned_text.strip()
        print(f"ğŸ§¹ åŸºç¡€æ¸…ç†åé•¿åº¦: {len(cleaned_text)} å­—ç¬¦")

        # å°è¯•è§£ææ¸…ç†åçš„æ–‡æœ¬
        try:
            result = json.loads(cleaned_text)
            print(f"âœ… æ–¹æ³•2æˆåŠŸ: åŸºç¡€æ¸…ç†åè§£ææˆåŠŸ")
            return result
        except json.JSONDecodeError as e:
            print(f"âŒ æ–¹æ³•2å¤±è´¥: {str(e)}")

        # æ–¹æ³•3: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–JSONå¯¹è±¡
        print(f"ğŸ” æ–¹æ³•3: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–JSONå¯¹è±¡...")

        # å¤šç§JSONæå–æ¨¡å¼
        json_patterns = [
            # æ ‡å‡†JSONå¯¹è±¡ï¼ˆæ”¯æŒåµŒå¥—ï¼‰
            (r'\{(?:[^{}]|(?R))*\}', re.DOTALL),
            # æ›´å®½æ¾çš„JSONåŒ¹é…
            (r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', re.DOTALL),
            # ç®€åŒ–åŒ¹é…ï¼ˆå¯»æ‰¾åŒ…å«"indicators"çš„å¯¹è±¡ï¼‰
            (r'\{[^}]*"indicators"[^}]*\}', re.DOTALL),
        ]

        for i, (pattern, flags) in enumerate(json_patterns, 1):
            try:
                # ä½¿ç”¨æ›´å¼ºå¤§çš„é€’å½’æ­£åˆ™è¡¨è¾¾å¼
                matches = self._extract_json_objects_recursive(text)
                print(f"ğŸ” æ¨¡å¼{i}: æ‰¾åˆ° {len(matches)} ä¸ªæ½œåœ¨JSONå¯¹è±¡")

                for j, json_str in enumerate(matches):
                    print(f"   å°è¯•å¯¹è±¡ {j+1}: é•¿åº¦ {len(json_str)} å­—ç¬¦")
                    try:
                        result = json.loads(json_str)
                        if 'indicators' in result:
                            print(f"âœ… æ–¹æ³•3.{i}.{j+1}æˆåŠŸ: æ‰¾åˆ°åŒ…å«indicatorsçš„JSONå¯¹è±¡")
                            return result
                    except json.JSONDecodeError as e:
                        print(f"   å¯¹è±¡ {j+1} è§£æå¤±è´¥: {str(e)[:100]}...")
                        continue

            except Exception as e:
                print(f"âŒ æ–¹æ³•3.{i}å¤±è´¥: {str(e)}")
                continue

        # æ–¹æ³•4: æ‹¬å·åŒ¹é…æ³•
        print(f"ğŸ” æ–¹æ³•4: æ‹¬å·åŒ¹é…æ³•...")
        json_candidates = self._extract_by_bracket_matching(text)
        for i, candidate in enumerate(json_candidates):
            try:
                result = json.loads(candidate)
                if 'indicators' in result:
                    print(f"âœ… æ–¹æ³•4.{i+1}æˆåŠŸ: æ‹¬å·åŒ¹é…æ‰¾åˆ°æœ‰æ•ˆJSON")
                    return result
            except json.JSONDecodeError:
                continue

        # æ–¹æ³•5: æœ€åå°è¯• - ä¿®å¤å¸¸è§çš„JSONé”™è¯¯
        print(f"ğŸ”§ æ–¹æ³•5: å°è¯•ä¿®å¤å¸¸è§JSONé”™è¯¯...")
        try:
            repaired_json = self._repair_json_syntax(cleaned_text)
            if repaired_json:
                result = json.loads(repaired_json)
                print(f"âœ… æ–¹æ³•5æˆåŠŸ: JSONä¿®å¤åè§£ææˆåŠŸ")
                return result
        except Exception as e:
            print(f"âŒ æ–¹æ³•5å¤±è´¥: {str(e)}")

        print(f"âŒ æ‰€æœ‰JSONæå–æ–¹æ³•éƒ½å¤±è´¥äº†")
        return None

    def _extract_json_objects_recursive(self, text):
        """é€’å½’æå–æ‰€æœ‰JSONå¯¹è±¡"""
        json_objects = []
        start_idx = 0
        bracket_count = 0
        in_string = False
        escape_char = False
        start_pos = -1

        for i, char in enumerate(text):
            if escape_char:
                escape_char = False
                continue

            if char == '\\':
                escape_char = True
                continue

            if char == '"' and not escape_char:
                in_string = not in_string
                continue

            if in_string:
                continue

            if char == '{':
                if bracket_count == 0:
                    start_pos = i
                bracket_count += 1
            elif char == '}':
                bracket_count -= 1
                if bracket_count == 0 and start_pos != -1:
                    json_str = text[start_pos:i+1]
                    json_objects.append(json_str)
                    start_pos = -1

        return json_objects

    def _extract_by_bracket_matching(self, text):
        """ä½¿ç”¨æ‹¬å·åŒ¹é…æå–JSONå¯¹è±¡"""
        candidates = []
        for i, char in enumerate(text):
            if char == '{':
                bracket_count = 0
                in_string = False
                escape_char = False

                for j in range(i, len(text)):
                    char_j = text[j]

                    if escape_char:
                        escape_char = False
                        continue

                    if char_j == '\\':
                        escape_char = True
                        continue

                    if char_j == '"' and not escape_char:
                        in_string = not in_string
                        continue

                    if in_string:
                        continue

                    if char_j == '{':
                        bracket_count += 1
                    elif char_j == '}':
                        bracket_count -= 1
                        if bracket_count == 0:
                            candidates.append(text[i:j+1])
                            break

        return candidates

    def _repair_json_syntax(self, text):
        """å°è¯•ä¿®å¤å¸¸è§çš„JSONè¯­æ³•é”™è¯¯"""
        if not text:
            return None

        # åŸºç¡€æ¸…ç†
        repaired = text.strip()

        # ç§»é™¤å¤šä½™çš„é€—å·
        repaired = re.sub(r',(\s*[}\]])', r'\1', repaired)

        # ç¡®ä¿å­—ç¬¦ä¸²è¢«æ­£ç¡®å¼•ç”¨
        repaired = re.sub(r'(\w+):', r'"\1":', repaired)

        # ä¿®å¤å¸¸è§çš„å¼•å·é—®é¢˜
        repaired = re.sub(r"'([^']*)'", r'"\1"', repaired)

        return repaired if repaired != text else None

    def _parse_vision_response(self, content):
        """è§£æè§†è§‰æ¨¡å‹çš„å“åº”"""
        try:
            print(f"ğŸ”§ å¼€å§‹è§£æè§†è§‰æ¨¡å‹å“åº”...")

            # ä½¿ç”¨æ™ºèƒ½JSONæå–åŠŸèƒ½
            result = self._extract_json_from_text(content)

            if not result:
                print(f"âŒ æ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆçš„JSON")
                print(f"ğŸ“„ åŸå§‹å“åº”å†…å®¹: {content}")
                return []

            indicators = result.get('indicators', [])

            if not indicators:
                print(f"âš ï¸  JSONè§£ææˆåŠŸä½†æœªæ‰¾åˆ°indicatorså­—æ®µ")
                print(f"ğŸ“„ JSONå†…å®¹: {json.dumps(result, ensure_ascii=False, indent=2)}")
                return []

            # éªŒè¯å’Œæ¸…ç†æŒ‡æ ‡æ•°æ®
            cleaned_indicators = []
            for indicator in indicators:
                if isinstance(indicator, dict) and 'indicator' in indicator:
                    # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
                    cleaned_indicators.append({
                        'indicator': indicator.get('indicator', ''),
                        'measured_value': indicator.get('measured_value', ''),
                        'normal_range': indicator.get('normal_range', ''),
                        'abnormal': indicator.get('abnormal', 'å¦')
                    })

            print(f"âœ… è§†è§‰å“åº”è§£ææˆåŠŸï¼Œæå–åˆ° {len(cleaned_indicators)} ä¸ªæœ‰æ•ˆæŒ‡æ ‡")
            return cleaned_indicators

        except Exception as e:
            print(f"âŒ è§†è§‰æ¨¡å‹å“åº”è§£æå¤±è´¥: {str(e)}")
            print(f"ğŸ“„ åŸå§‹å“åº”å‰500å­—ç¬¦: {content[:500]}...")
            return []

    def _merge_indicators(self, all_indicators):
        """åˆå¹¶å’Œå»é‡æŒ‡æ ‡"""
        # ä½¿ç”¨æŒ‡æ ‡åç§°ä½œä¸ºé”®è¿›è¡Œå»é‡
        indicator_map = {}

        for indicator in all_indicators:
            name = indicator.get('indicator', '').strip()
            if name:
                if name in indicator_map:
                    # å¦‚æœæŒ‡æ ‡å·²å­˜åœ¨ï¼Œé€‰æ‹©æ›´å®Œæ•´çš„ç‰ˆæœ¬
                    existing = indicator_map[name]
                    # ä¼˜å…ˆé€‰æ‹©æœ‰æµ‹é‡å€¼çš„ç‰ˆæœ¬
                    if indicator.get('measured_value') and not existing.get('measured_value'):
                        indicator_map[name] = indicator
                    # å¦‚æœéƒ½æœ‰æµ‹é‡å€¼ï¼Œä¼˜å…ˆé€‰æ‹©å¼‚å¸¸çš„ç‰ˆæœ¬
                    elif indicator.get('abnormal') == 'æ˜¯' and existing.get('abnormal') != 'æ˜¯':
                        indicator_map[name] = indicator
                else:
                    indicator_map[name] = indicator

        # è¿”å›å»é‡åçš„æŒ‡æ ‡åˆ—è¡¨
        return list(indicator_map.values())

    def save_vision_indicators(self, structured_data):
        """ä¿å­˜å¤šæ¨¡æ€æ¨¡å‹æå–çš„å¥åº·æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        try:
            self.update_progress('saving_data', 80, "ä¿å­˜å¥åº·æŒ‡æ ‡æ•°æ®...")

            indicators = structured_data.get('indicators', [])
            saved_count = 0
            skipped_count = 0
            error_count = 0

            for indicator_data in indicators:
                try:
                    indicator_name = indicator_data.get('indicator', '')
                    measured_value = indicator_data.get('measured_value', '')
                    normal_range = indicator_data.get('normal_range', None)
                    is_abnormal = indicator_data.get('abnormal', None)

                    # è·³è¿‡ç¼ºå°‘æŒ‡æ ‡åç§°çš„æ•°æ®
                    if not indicator_name or not str(indicator_name).strip():
                        print(f"âš ï¸  è·³è¿‡æŒ‡æ ‡: ç¼ºå°‘æŒ‡æ ‡åç§°")
                        skipped_count += 1
                        continue

                    # å¤„ç†measured_valueçš„nullå€¼ï¼Œå¢åŠ å®¹é”™æ€§
                    if measured_value is None or measured_value == 'null' or not str(measured_value).strip():
                        clean_value = ''  # ä½¿ç”¨ç©ºå­—ç¬¦ä¸²è€Œä¸æ˜¯'None'
                        unit = ''
                        print(f"âš ï¸  æŒ‡æ ‡ '{indicator_name}' çš„æ£€æµ‹å€¼ä¸ºç©ºï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²")
                    else:
                        # å¤„ç† null å€¼
                        if normal_range is None or normal_range == 'null':
                            normal_range = ''

                        # è½¬æ¢å¼‚å¸¸çŠ¶æ€
                        if is_abnormal is None or is_abnormal == 'null':
                            # å¦‚æœ LLM æ²¡æœ‰æ˜ç¡®æ ‡æ³¨å¼‚å¸¸ï¼ˆæŠ¥å‘Šä¸­æ²¡æœ‰å‚è€ƒèŒƒå›´ï¼‰ï¼Œåˆ™ä¸åˆ¤æ–­çŠ¶æ€
                            # ç”±äºæ•°æ®åº“å­—æ®µä¸å…è®¸NULLä¸”æœ‰default='normal'ï¼Œè¿™é‡Œç•™ç©ºä¼šä½¿ç”¨é»˜è®¤å€¼
                            status = None  # ä½¿ç”¨æ¨¡å‹é»˜è®¤å€¼
                        elif isinstance(is_abnormal, str):
                            if is_abnormal.lower() in ['æ˜¯', 'yes', 'å¼‚å¸¸', 'true', 'positive', 'é˜³æ€§']:
                                status = 'abnormal'
                            elif is_abnormal.lower() in ['å¦', 'no', 'æ­£å¸¸', 'false', 'negative', 'é˜´æ€§']:
                                status = 'normal'
                            else:
                                # æ— æ³•è¯†åˆ«çš„å­—ç¬¦ä¸²ï¼Œä¸åˆ¤æ–­çŠ¶æ€
                                status = None  # ä½¿ç”¨æ¨¡å‹é»˜è®¤å€¼
                        elif isinstance(is_abnormal, bool):
                            status = 'abnormal' if is_abnormal else 'normal'
                        else:
                            status = None  # ä½¿ç”¨æ¨¡å‹é»˜è®¤å€¼

                        # ç¡®å®šæŒ‡æ ‡ç±»å‹
                        service = DocumentProcessingService(self.document_processing)
                        indicator_type = service._get_indicator_type_from_name(indicator_name)

                        # ç¡®å®šå•ä½
                        unit = service._extract_unit_from_value(measured_value, indicator_name)

                        # æ¸…ç†æµ‹é‡å€¼
                        clean_value = service._clean_measured_value(measured_value, unit)

                    # åˆ›å»ºå¥åº·æŒ‡æ ‡
                    indicator = HealthIndicator.objects.create(
                        checkup=self.document_processing.health_checkup,
                        indicator_type=indicator_type,
                        indicator_name=indicator_name,
                        value=clean_value,
                        unit=unit if unit else '',  # ç¡®ä¿unitä¸æ˜¯None
                        reference_range=normal_range or '',  # ç¡®ä¿ None è½¬ä¸ºç©ºå­—ç¬¦ä¸²
                        status=status if status else 'normal'  # ä¿å­˜è®¡ç®—å‡ºçš„çŠ¶æ€å€¼
                    )
                    saved_count += 1
                    status_display = status if status else 'normal(é»˜è®¤)'
                    print(f"âœ… å·²ä¿å­˜æŒ‡æ ‡ {saved_count}: {indicator_name} = {clean_value if clean_value else '(ç©º)'} {unit if unit else ''} (å‚è€ƒèŒƒå›´:{normal_range or 'ç©º'}, çŠ¶æ€:{status_display})")

                except Exception as e:
                    # å•ä¸ªæŒ‡æ ‡ä¿å­˜å¤±è´¥ä¸å½±å“å…¶ä»–æŒ‡æ ‡
                    error_count += 1
                    print(f"âŒ ä¿å­˜æŒ‡æ ‡å¤±è´¥: {indicator_data.get('indicator', 'æœªçŸ¥æŒ‡æ ‡')} - é”™è¯¯: {str(e)}")
                    continue

            # æ›´æ–°è¿›åº¦
            progress = 80 + int((saved_count / len(indicators)) * 15) if indicators else 95
            summary_msg = f"å·²ä¿å­˜ {saved_count}/{len(indicators)} é¡¹æŒ‡æ ‡"
            if skipped_count > 0:
                summary_msg += f"ï¼Œè·³è¿‡ {skipped_count} é¡¹"
            if error_count > 0:
                summary_msg += f"ï¼Œå¤±è´¥ {error_count} é¡¹"
            self.update_progress('saving_data', progress, summary_msg)

            self.update_progress('completed', 100, f"å¤„ç†å®Œæˆ - æˆåŠŸ:{saved_count}, è·³è¿‡:{skipped_count}, å¤±è´¥:{error_count}")
            return saved_count

        except Exception as e:
            self.update_progress('failed', 0, f"ä¿å­˜æ•°æ®å¤±è´¥: {str(e)}", is_error=True)
            raise


def get_vision_model_api_status():
    """æ£€æŸ¥å¤šæ¨¡æ€å¤§æ¨¡å‹APIçŠ¶æ€"""
    try:
        config = SystemSettings.get_vl_model_config()
        if not config['api_url'] or not config['model_name']:
            return False

        # å‘é€æµ‹è¯•è¯·æ±‚ - ç›´æ¥ä½¿ç”¨é…ç½®çš„API URL
        check_url = config['api_url']
        data = {
            "model": config['model_name'],
            "messages": [{"role": "user", "content": "test"}],
            "max_tokens": 5
        }

        headers = {'Content-Type': 'application/json'}
        if config.get('api_key'):
            headers['Authorization'] = f"Bearer {config['api_key']}"

        response = requests.post(check_url, json=data, headers=headers, timeout=10)
        return response.status_code == 200
    except:
        return False


class AIService:
    """AIæœåŠ¡ç±»ï¼Œç”¨äºç”Ÿæˆå¥åº·å»ºè®®"""

    def __init__(self):
        # è·å–LLMé…ç½®
        self.llm_api_url = SystemSettings.get_setting('llm_api_url', 'http://172.25.48.1:1234')
        self.llm_api_key = SystemSettings.get_setting('llm_api_key', '')
        self.llm_model_name = SystemSettings.get_setting('llm_model_name', 'qwen3-4b-instruct')
        # ä½¿ç”¨ç»Ÿä¸€çš„AIæ¨¡å‹è¶…æ—¶é…ç½®
        self.ai_timeout = int(SystemSettings.get_setting('ai_model_timeout', '300'))

    def get_health_advice(self, indicators):
        """æ ¹æ®å¥åº·æŒ‡æ ‡ç”ŸæˆAIå»ºè®®"""
        try:
            # æ„å»ºprompt
            prompt = self._build_advice_prompt(indicators)

            # å‡†å¤‡è¯·æ±‚æ•°æ®
            llm_data = {
                "model": self.llm_model_name,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¥åº·é¡¾é—®åŒ»ç”Ÿï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„ä½“æ£€æŒ‡æ ‡æ•°æ®æä¾›å¥åº·å»ºè®®ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": 0.3,
                "max_tokens": 2000
            }

            # å‡†å¤‡è¯·æ±‚å¤´
            headers = {
                "Content-Type": "application/json"
            }

            if self.llm_api_key:
                headers["Authorization"] = f"Bearer {self.llm_api_key}"

            # APIè°ƒç”¨ç›´æ¥ä½¿ç”¨é…ç½®çš„å®Œæ•´åœ°å€
            response = requests.post(
                self.llm_api_url,
                json=llm_data,
                headers=headers,
                timeout=self.ai_timeout
            )

            if response.status_code == 200:
                result = response.json()
                advice = result['choices'][0]['message']['content']
                return advice.strip()
            else:
                raise Exception(f"AIå»ºè®®ç”Ÿæˆå¤±è´¥: {response.status_code} - {response.text}")

        except Exception as e:
            return f"å¾ˆæŠ±æ­‰ï¼ŒAIå»ºè®®ç”Ÿæˆå¤±è´¥: {str(e)}"

    def _build_advice_prompt(self, indicators):
        """æ„å»ºå¥åº·å»ºè®®çš„prompt"""
        # æ ¼å¼åŒ–æŒ‡æ ‡æ•°æ®
        indicators_text = ""
        abnormal_indicators = []

        for indicator in indicators:
            status = "å¼‚å¸¸" if indicator.status == 'abnormal' else "æ­£å¸¸"
            indicators_text += f"- {indicator.indicator_name}: {indicator.value} {indicator.unit} (å‚è€ƒèŒƒå›´: {indicator.reference_range}) - {status}\n"

            if indicator.status == 'abnormal':
                abnormal_indicators.append(indicator.indicator_name)

        # æ ¹æ®å¼‚å¸¸æŒ‡æ ‡è°ƒæ•´å»ºè®®é‡ç‚¹
        if abnormal_indicators:
            focus_text = f"ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹å¼‚å¸¸æŒ‡æ ‡: {', '.join(abnormal_indicators)}"
        else:
            focus_text = "æ‰€æœ‰æŒ‡æ ‡éƒ½åœ¨æ­£å¸¸èŒƒå›´å†…"

        return f"""
è¯·æ ¹æ®ä»¥ä¸‹ä½“æ£€æŒ‡æ ‡æ•°æ®ï¼Œä¸ºç”¨æˆ·æä¾›ä¸“ä¸šçš„å¥åº·å»ºè®®å’Œç”Ÿæ´»æ–¹å¼æŒ‡å¯¼ã€‚

ä½“æ£€æŒ‡æ ‡æ•°æ®:
{indicators_text}

{focus_text}

è¯·æä¾›ä»¥ä¸‹æ–¹é¢çš„å»ºè®®ï¼š
1. **æŒ‡æ ‡è§£è¯»**: ç®€è¦è§£é‡Šå„é¡¹æŒ‡æ ‡çš„å«ä¹‰
2. **å¼‚å¸¸åˆ†æ**: é’ˆå¯¹å¼‚å¸¸æŒ‡æ ‡æä¾›å¯èƒ½çš„åŸå› å’Œå»ºè®®
3. **é¥®é£Ÿå»ºè®®**: åŸºäºä½“æ£€ç»“æœæä¾›é¥®é£Ÿè°ƒæ•´å»ºè®®
4. **è¿åŠ¨å»ºè®®**: æ¨èé€‚åˆçš„è¿åŠ¨æ–¹å¼å’Œé¢‘ç‡
5. **ç”Ÿæ´»ä¹ æƒ¯**: æä¾›ä½œæ¯ã€æˆ’çƒŸé™é…’ç­‰ç”Ÿæ´»æ–¹å¼å»ºè®®
6. **å®šæœŸå¤æŸ¥**: å»ºè®®éœ€è¦é‡ç‚¹å…³æ³¨å’Œå®šæœŸå¤æŸ¥çš„æŒ‡æ ‡

è¯·ç”¨é€šä¿—æ˜“æ‡‚ã€ä¸“ä¸šè€Œä¸ç”Ÿç¡¬çš„è¯­è¨€ï¼Œé¿å…è¿‡åº¦åŒ»å­¦æœ¯è¯­ï¼Œç»™å‡ºå®ç”¨çš„å»ºè®®ã€‚å»ºè®®è¦å…·ä½“å¯è¡Œï¼Œé¿å…è¿‡äºç¬¼ç»Ÿã€‚

æ³¨æ„ï¼š
- å¦‚æœæ‰€æœ‰æŒ‡æ ‡æ­£å¸¸ï¼Œé‡ç‚¹ç»™å‡ºé¢„é˜²ä¿å¥å»ºè®®
- å¦‚æœæœ‰å¼‚å¸¸æŒ‡æ ‡ï¼Œé‡ç‚¹å…³æ³¨ç›¸å…³é£é™©å› ç´ 
- å»ºè®®ç”¨æˆ·å®šæœŸä½“æ£€ï¼ŒéµåŒ»å˜±è¿›è¡Œå¤æŸ¥
- å¼ºè°ƒæœ¬å»ºè®®ä»…ä¾›å‚è€ƒï¼Œå…·ä½“è¯Šç–—è¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
"""


def call_llm_for_integration(prompt, timeout=None):
    """
    è°ƒç”¨LLM APIè¿›è¡Œæ•°æ®æ•´åˆåˆ†æ

    Args:
        prompt: å‘é€ç»™LLMçš„æç¤ºè¯
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨ç³»ç»Ÿé…ç½®

    Returns:
        str: LLMçš„å“åº”æ–‡æœ¬
    """
    import requests
    import json
    from .models import SystemSettings

    # è·å–LLMé…ç½®
    llm_api_url = SystemSettings.get_setting('llm_api_url', 'http://172.25.48.1:1234')
    llm_api_key = SystemSettings.get_setting('llm_api_key', '')
    llm_model_name = SystemSettings.get_setting('llm_model_name', 'MiniMaxAI/MiniMax-M2')

    # ä½¿ç”¨ç»Ÿä¸€è¶…æ—¶é…ç½®
    if timeout is None:
        timeout = int(SystemSettings.get_setting('ai_model_timeout', '300'))

    # ä»ç³»ç»Ÿè®¾ç½®è¯»å–max_tokens
    max_tokens = int(SystemSettings.get_setting('llm_max_tokens', '16000'))

    print(f"\n{'='*80}")
    print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] å¼€å§‹")
    print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] API URL: {llm_api_url}")
    print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] æ¨¡å‹: {llm_model_name}")
    print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] è¶…æ—¶: {timeout}ç§’")
    print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] æœ€å¤§Tokens: {max_tokens}")
    print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] API Key: {'å·²è®¾ç½®' if llm_api_key else 'æœªè®¾ç½®'}")

    # æ„å»ºè¯·æ±‚æ•°æ®
    llm_data = {
        "model": llm_model_name,
        "messages": [
            {
                "role": "system",
                "content": "ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œä¸æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": 0.1,
        "max_tokens": max_tokens  # ä½¿ç”¨ç³»ç»Ÿé…ç½®çš„max_tokens
    }

    # å‡†å¤‡è¯·æ±‚å¤´
    headers = {
        "Content-Type": "application/json"
    }

    # åªæœ‰åœ¨æœ‰API Keyæ—¶æ‰æ·»åŠ Authorizationå¤´
    if llm_api_key:
        headers["Authorization"] = f"Bearer {llm_api_key}"

    try:
        # ç›´æ¥ä½¿ç”¨é…ç½®çš„å®Œæ•´APIåœ°å€
        api_url = llm_api_url

        print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] å®Œæ•´APIåœ°å€: {api_url}")
        print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")
        print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] è¯·æ±‚ä½“å¤§å°: {len(json.dumps(llm_data))} å­—ç¬¦")
        print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] æ­£åœ¨å‘é€è¯·æ±‚...")

        # å‘é€è¯·æ±‚
        import time
        start_time = time.time()

        response = requests.post(
            api_url,
            json=llm_data,
            headers=headers,
            timeout=timeout
        )

        end_time = time.time()
        duration = end_time - start_time

        print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] è¯·æ±‚å®Œæˆ")
        print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] çŠ¶æ€ç : {response.status_code}")
        print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] å“åº”æ—¶é—´: {duration:.2f}ç§’")
        print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] å“åº”å¤§å°: {len(response.text)} å­—ç¬¦")

        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content']
            print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] âœ“ æˆåŠŸè·å–å“åº”")
            print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] å“åº”å†…å®¹å‰500å­—ç¬¦:")
            print(f"{content[:500]}")
            print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] å“åº”å†…å®¹å500å­—ç¬¦:")
            print(f"{content[-500:]}")
            return content
        else:
            print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] âœ— APIè¿”å›é”™è¯¯")
            print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] é”™è¯¯è¯¦æƒ…: {response.text}")
            raise Exception(f"LLM APIè¿”å›é”™è¯¯: {response.status_code} - {response.text}")

    except requests.exceptions.Timeout:
        print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] âœ— è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
        raise Exception(f"LLM APIè¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
    except Exception as e:
        print(f"[æ•°æ®æ•´åˆ LLMè°ƒç”¨] âœ— è°ƒç”¨å¤±è´¥: {str(e)}")
        raise Exception(f"è°ƒç”¨LLM APIå¤±è´¥: {str(e)}")


def call_gemini_api(prompt, system_message=None, timeout=None):
    """
    è°ƒç”¨ Google Gemini API

    Args:
        prompt: å‘é€ç»™Geminiçš„æç¤ºè¯
        system_message: ç³»ç»Ÿæ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨ç³»ç»Ÿé…ç½®

    Returns:
        str: Geminiçš„å“åº”æ–‡æœ¬
    """
    import requests
    import json
    from .models import SystemSettings

    # è·å–Geminié…ç½®
    gemini_config = SystemSettings.get_gemini_config()
    api_key = gemini_config['api_key']
    model_name = gemini_config['model_name']

    if not api_key:
        raise Exception("Gemini APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨ç³»ç»Ÿè®¾ç½®ä¸­é…ç½®")

    # ä½¿ç”¨ç»Ÿä¸€è¶…æ—¶é…ç½®
    if timeout is None:
        timeout = int(SystemSettings.get_setting('ai_model_timeout', '300'))

    # ä»ç³»ç»Ÿè®¾ç½®è¯»å–max_tokens
    max_tokens = int(SystemSettings.get_setting('llm_max_tokens', '16000'))

    print(f"\n{'='*80}")
    print(f"[Gemini APIè°ƒç”¨] å¼€å§‹")
    print(f"[Gemini APIè°ƒç”¨] æ¨¡å‹: {model_name}")
    print(f"[Gemini APIè°ƒç”¨] API Key: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
    print(f"[Gemini APIè°ƒç”¨] è¶…æ—¶: {timeout}ç§’")
    print(f"[Gemini APIè°ƒç”¨] æœ€å¤§Tokens: {max_tokens}")

    # æ„å»ºè¯·æ±‚å†…å®¹
    parts = []

    # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if system_message:
        parts.append({"text": system_message})

    # æ·»åŠ ç”¨æˆ·æç¤º
    parts.append({"text": prompt})

    # Gemini API è¯·æ±‚æ ¼å¼
    gemini_data = {
        "contents": [{
            "parts": parts
        }],
        "generationConfig": {
            "temperature": 0.7,
            "maxOutputTokens": max_tokens  # ä½¿ç”¨ç³»ç»Ÿé…ç½®çš„max_tokens
        }
    }

    # æ„å»ºAPI URL
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"

    print(f"[Gemini APIè°ƒç”¨] è¯·æ±‚URL: {api_url}")
    print(f"[Gemini APIè°ƒç”¨] Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")

    try:
        import time
        start_time = time.time()

        response = requests.post(
            api_url,
            json=gemini_data,
            headers={"Content-Type": "application/json"},
            timeout=timeout
        )

        end_time = time.time()
        duration = end_time - start_time

        print(f"[Gemini APIè°ƒç”¨] è¯·æ±‚å®Œæˆ")
        print(f"[Gemini APIè°ƒç”¨] çŠ¶æ€ç : {response.status_code}")
        print(f"[Gemini APIè°ƒç”¨] å“åº”æ—¶é—´: {duration:.2f}ç§’")

        if response.status_code == 200:
            result = response.json()

            # æ£€æŸ¥æ˜¯å¦æœ‰å€™é€‰ç»“æœ
            if 'candidates' in result and len(result['candidates']) > 0:
                content = result['candidates'][0]['content']['parts'][0]['text']
                print(f"[Gemini APIè°ƒç”¨] âœ“ æˆåŠŸè·å–å“åº”")
                print(f"[Gemini APIè°ƒç”¨] å“åº”é•¿åº¦: {len(content)} å­—ç¬¦")
                return content
            else:
                print(f"[Gemini APIè°ƒç”¨] âœ— å“åº”ä¸­æ²¡æœ‰å€™é€‰ç»“æœ")
                print(f"[Gemini APIè°ƒç”¨] å“åº”å†…å®¹: {result}")
                raise Exception("Gemini APIè¿”å›äº†ç©ºå“åº”")
        else:
            print(f"[Gemini APIè°ƒç”¨] âœ— APIè¿”å›é”™è¯¯")
            print(f"[Gemini APIè°ƒç”¨] é”™è¯¯è¯¦æƒ…: {response.text}")
            raise Exception(f"Gemini APIè¿”å›é”™è¯¯: {response.status_code} - {response.text}")

    except requests.exceptions.Timeout:
        print(f"[Gemini APIè°ƒç”¨] âœ— è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
        raise Exception(f"Gemini APIè¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
    except Exception as e:
        print(f"[Gemini APIè°ƒç”¨] âœ— è°ƒç”¨å¤±è´¥: {str(e)}")
        raise Exception(f"è°ƒç”¨Gemini APIå¤±è´¥: {str(e)}")


def call_gemini_vision_api(image_base64, prompt, timeout=None):
    """
    è°ƒç”¨ Google Gemini Vision API è¿›è¡Œå¤šæ¨¡æ€ç†è§£

    Args:
        image_base64: å›¾ç‰‡çš„base64ç¼–ç 
        prompt: æ–‡æœ¬æç¤º
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨ç³»ç»Ÿé…ç½®

    Returns:
        str: Geminiçš„å“åº”æ–‡æœ¬
    """
    import requests
    import json
    from .models import SystemSettings

    # è·å–Geminié…ç½®
    gemini_config = SystemSettings.get_gemini_config()
    api_key = gemini_config['api_key']
    model_name = gemini_config['model_name']

    if not api_key:
        raise Exception("Gemini APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨ç³»ç»Ÿè®¾ç½®ä¸­é…ç½®")

    # ä½¿ç”¨ç»Ÿä¸€è¶…æ—¶é…ç½®
    if timeout is None:
        timeout = int(SystemSettings.get_setting('ai_model_timeout', '300'))

    # ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹çš„max_tokensé…ç½®
    max_tokens = int(SystemSettings.get_setting('vl_model_max_tokens', '4000'))

    print(f"\n{'='*80}")
    print(f"[Gemini Vision APIè°ƒç”¨] å¼€å§‹")
    print(f"[Gemini Vision APIè°ƒç”¨] æ¨¡å‹: {model_name}")
    print(f"[Gemini Vision APIè°ƒç”¨] è¶…æ—¶: {timeout}ç§’")
    print(f"[Gemini Vision APIè°ƒç”¨] æœ€å¤§Tokens: {max_tokens}")

    # æ„å»ºè¯·æ±‚å†…å®¹
    gemini_data = {
        "contents": [{
            "parts": [
                {
                    "inline_data": {
                        "mime_type": "image/jpeg",
                        "data": image_base64
                    }
                },
                {
                    "text": prompt
                }
            ]
        }],
        "generationConfig": {
            "temperature": 0.7,
            "maxOutputTokens": max_tokens  # ä½¿ç”¨ç³»ç»Ÿé…ç½®çš„max_tokens
        }
    }

    # æ„å»ºAPI URL
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"

    print(f"[Gemini Vision APIè°ƒç”¨] è¯·æ±‚URL: {api_url}")

    try:
        import time
        start_time = time.time()

        response = requests.post(
            api_url,
            json=gemini_data,
            headers={"Content-Type": "application/json"},
            timeout=timeout
        )

        end_time = time.time()
        duration = end_time - start_time

        print(f"[Gemini Vision APIè°ƒç”¨] çŠ¶æ€ç : {response.status_code}")
        print(f"[Gemini Vision APIè°ƒç”¨] å“åº”æ—¶é—´: {duration:.2f}ç§’")

        if response.status_code == 200:
            result = response.json()

            if 'candidates' in result and len(result['candidates']) > 0:
                content = result['candidates'][0]['content']['parts'][0]['text']
                print(f"[Gemini Vision APIè°ƒç”¨] âœ“ æˆåŠŸè·å–å“åº”")
                return content
            else:
                raise Exception("Gemini Vision APIè¿”å›äº†ç©ºå“åº”")
        else:
            raise Exception(f"Gemini Vision APIè¿”å›é”™è¯¯: {response.status_code} - {response.text}")

    except requests.exceptions.Timeout:
        raise Exception(f"Gemini Vision APIè¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
    except Exception as e:
        raise Exception(f"è°ƒç”¨Gemini Vision APIå¤±è´¥: {str(e)}")
